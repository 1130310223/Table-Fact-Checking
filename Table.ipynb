{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('input_file_wenhu.csv', mode='w') as fw:\n",
    "    with open('input_file_shiyang.csv', mode='w') as fs:\n",
    "        with open('input_file_yunkai.csv', mode='w') as fy:\n",
    "            \n",
    "            #output_wenhu = output[:5000]\n",
    "            #fileds = ['url1', 'q1', 'a1', 'url2', 'q2', 'a2', 'url3', 'q3', 'a3', 'url4', 'q4', 'a4', 'url5', 'q5', 'a5']\n",
    "            #writer = csv.DictWriter(fw, fieldnames=fileds)\n",
    "            #writer.writeheader()\n",
    "            #for i in range(0, len(output_wenhu) - 5, 5):\n",
    "            #    writer.writerow({'url1':output_wenhu[i]['url'], 'q1':output_wenhu[i]['q'], 'a1':output_wenhu[i]['a'],\n",
    "            #                    'url2':output_wenhu[i+1]['url'], 'q2':output_wenhu[i+1]['q'], 'a2':output_wenhu[i+1]['a'],\n",
    "            #                    'url3':output_wenhu[i+2]['url'], 'q3':output_wenhu[i+2]['q'], 'a3':output_wenhu[i+2]['a'],\n",
    "            #                    'url4':output_wenhu[i+3]['url'], 'q4':output_wenhu[i+3]['q'], 'a4':output_wenhu[i+3]['a'],\n",
    "            #                    'url5':output_wenhu[i+4]['url'], 'q5':output_wenhu[i+4]['q'], 'a5':output_wenhu[i+4]['a']})\n",
    "            \n",
    "            num = 10\n",
    "            \n",
    "            output_shiyang = output[5000:20000]\n",
    "            fields = []\n",
    "            for i in range(1, num+1):\n",
    "                fields.extend(['url{}'.format(i), 'q{}'.format(i), 'a{}'.format(i)])\n",
    "            writer = csv.DictWriter(fs, fieldnames=fields)\n",
    "            writer.writeheader()\n",
    "            for i in range(0, len(output_shiyang) - num, num):\n",
    "                elem = {}\n",
    "                for j in range(1, num+1):\n",
    "                    elem['url{}'.format(j)] = output_shiyang[i+j-1]['url']\n",
    "                    elem['q{}'.format(j)] = output_shiyang[i+j-1]['q']\n",
    "                    elem['a{}'.format(j)] = output_shiyang[i+j-1]['a']\n",
    "                \n",
    "                writer.writerow(elem) \n",
    "            \n",
    "            \n",
    "            output_yunkai = output[20000:]\n",
    "            fields = []\n",
    "            for i in range(1, num+1):\n",
    "                fields.extend(['url{}'.format(i), 'q{}'.format(i), 'a{}'.format(i)])\n",
    "            writer = csv.DictWriter(fy, fieldnames=fields)\n",
    "            writer.writeheader()\n",
    "            for i in range(0, len(output_yunkai) - num, num):\n",
    "                elem = {}\n",
    "                for j in range(1, num+1):\n",
    "                    elem['url{}'.format(j)] = output_yunkai[i+j-1]['url']\n",
    "                    elem['q{}'.format(j)] = output_yunkai[i+j-1]['q']\n",
    "                    elem['a{}'.format(j)] = output_yunkai[i+j-1]['a']\n",
    "                \n",
    "                writer.writerow(elem) \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex(inp):\n",
    "    inp = re.sub(r\"> +\", r\">\", inp)\n",
    "    inp = re.sub(r\" +<\", r\"<\", inp)\n",
    "    inp = re.sub(r\">@\", r\">\", inp)\n",
    "    inp = re.sub(r\"\\*\", r\"\", inp)\n",
    "    inp = re.sub(r\"#\", r\"\", inp)\n",
    "    inp = re.sub(r\"‡\", r\"\", inp)\n",
    "    #inp = re.sub(r\".0([^0-9])\", r\"\\1\", inp)\n",
    "    for month, abb in [(\"January\", \"Jan\"), (\"February\", \"Feb\"), (\"March\", \"March\"), (\"April\", \"April\"), \n",
    "                   (\"May\", \"May\"), (\"June\",\"June\") , (\"July\", \"July\"), (\"August\", \"Aug\"), \n",
    "                   (\"September\", \"Sep\"), (\"October\", \"Oct\"), (\"November\", \"Nov\"), (\"December\", \"Dec\")]:\n",
    "        inp = re.sub(r\"({})([0-9]+)\".format(month), r\"\\1 \\2\", inp)\n",
    "        inp = re.sub(r\"({})([0-9]+)\".format(abb), r\"\\1 \\2\", inp)\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "import jsonlines\n",
    "import csv\n",
    "import re\n",
    "\"\"\"\n",
    "with open('all_html_original.csv', 'w') as fw:\n",
    "    fields = ['url', 'content']\n",
    "    writer = csv.DictWriter(fw, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "\"\"\"\n",
    "with open('WikiTableQuestions/wikidata/train.tables.jsonl') as f:\n",
    "    data = jsonlines.Reader(f)\n",
    "    for d in data:\n",
    "        f = '<table class=\"wikitable\"><tr>'\n",
    "        for h in d['header']:\n",
    "            f += \"<th> {} </th>\".format(h)\n",
    "        f += \"</tr>\"\n",
    "        for r in d['rows']:\n",
    "            f += \"<tr>\"\n",
    "            for elem in r:\n",
    "                f += \"<td> {} </td>\".format(elem)\n",
    "            f += \"</tr>\"\n",
    "        f += \"</table>\"\n",
    "        #writer.writerow({'url': d['id'], \"content\": f})\n",
    "        with open('WikiTableQuestions/wikidata/all_html/{}.html'.format(d['id']), 'w') as fw:\n",
    "            print >> fw, regex(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def regex_equation(line):\n",
    "    line = re.sub(r\"([^+-])([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)=\", r\"\\1\\2+\\3+\\4+\\5=\", line)\n",
    "    line = re.sub(r\"([^+-])([0-9]+)-([0-9]+)-([0-9]+)=\", r\"\\1\\2+\\3+\\4=\", line)\n",
    "    line = re.sub(r\"([^+-])([0-9]+)-([0-9]+)=\", r\"\\1\\2+\\3=\", line)\n",
    "    #line = re.sub(r\"([^+-])([0-9]+)-([0-9]+)+([0-9]+)=\", r\"\\1\\2+\\3+\\4=\", line)\n",
    "    #line = re.sub(r\"([^+-])([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)=\", r\"\\1+\\2+\\3+\\4=\", line)    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_equation(\"67-54-69-68=270)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/tmp/list.txt') as f:\n",
    "    for line in f:\n",
    "        with open('WikiTableQuestions/wikidata/all_html/' + line.strip(), 'r') as f1:\n",
    "            content = f1.readline().strip()\n",
    "        with open('WikiTableQuestions/wikidata/all_html/' + line.strip(), 'w') as f1:\n",
    "            print >> f1, regex_equation(content)\n",
    "        #print regex_equation(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('WikiTableQuestions/wikidata/train_gold.json') as f:\n",
    "    raw_output = json.load(f)\n",
    "    output = [\"/\".join([str(__) for __ in _]) for _ in raw_output]\n",
    "\n",
    "with open('WikiTableQuestions/wikidata/all_training.tsv', 'w') as fw:\n",
    "    print >> fw, \"id\\tutterance\\tcontext\\ttargetValue\"\n",
    "    with open('WikiTableQuestions/wikidata/train.jsonl') as f:\n",
    "        data = jsonlines.Reader(f)\n",
    "        idx = 1\n",
    "        for d, o in zip(data, output):\n",
    "            print >> fw, \"{}\\t{}\\t{}\\t{}\".format(idx, d['question'].replace('\\t', ''), d['table_id'], o)\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "\n",
    "files = pandas.read_table('WikiTableQuestions/wikidata/all_training.tsv', delimiter=\"\\t\")\n",
    "\n",
    "output = []\n",
    "for f in os.listdir('WikiTableQuestions/wikidata/all_html/'):\n",
    "    if \"html\" in f:\n",
    "        numbering = f.split('.')[0]\n",
    "        results = files[files.context == numbering]\n",
    "        \n",
    "        for q, a in zip(results.utterance, results.targetValue):\n",
    "            tmp = {}\n",
    "            tmp[\"url\"] = 'https://raw.githubusercontent.com/wenhuchen/Interface/master/WikiTableQuestions/wikidata/all_html/{}.html'.format(numbering)\n",
    "            tmp[\"q\"] = q\n",
    "            tmp[\"a\"] = a\n",
    "            output.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('WikiTableQuestions/data/all_training_new.tsv', 'w') as fw:\n",
    "    with open('WikiTableQuestions/data/all_training.tsv') as f:\n",
    "        for line in f:\n",
    "            if \"csv\" in line:\n",
    "                try:\n",
    "                    t1, t2, t3, t4 = line.strip().split('\\t')\n",
    "                except Exception:\n",
    "                    print line.strip()\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    f1, f2, f3 = t3.split('/')\n",
    "                except Exception:\n",
    "                    print t3.strip()\n",
    "                    continue\n",
    "                    \n",
    "                t3 = f2.split('-')[0] + \"-\" + f3\n",
    "                new_line = \"\\t\".join([t1, t2, t3, t4])\n",
    "                print >> fw, new_line\n",
    "            else:\n",
    "                print >> fw, line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "result = pandas.read_table('WikiTableQuestions/wikidata/all_training.tsv')\n",
    "\n",
    "new_result = result[~result.targetValue.isin(['None', 'n/a', ])]\n",
    "\n",
    "new_result.to_csv('WikiTableQuestions/wikidata/all_training_new.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for r in result['Answer.d1']:\n",
    "    print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas\n",
    "\n",
    "result = pandas.read_csv('results_v2.csv')\n",
    "filtered = result[result.AssignmentStatus==\"Approved\"]\n",
    "\n",
    "items = []\n",
    "for i, r in filtered.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for i in range(1, num+1):\n",
    "        if r['Input.a{}'.format(i)] not in ['None', 'n/a'] and \" par \" not in r['Answer.d{}'.format(i)].lower():\n",
    "            items.append((r['Input.url{}'.format(i)], r['Input.q{}'.format(i)], r['Input.a{}'.format(i)], r['Answer.d{}'.format(i)]))\n",
    "\n",
    "with open('v2_results.json', 'w') as f:\n",
    "    json.dump(items, f, indent=2)\n",
    "    \n",
    "with open('v2_rewrite_input.csv', 'w') as f:\n",
    "    #json.dump(items, f, indent=2)\n",
    "    fields = []\n",
    "    for j in range(1, num + 1):\n",
    "        fields.append(\"url{}\".format(j))\n",
    "        fields.append(\"s{}\".format(j))\n",
    "        \n",
    "    writer = csv.DictWriter(f, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "    for i in range(0, len(items) - num, num):\n",
    "        elem = {}\n",
    "        for j in range(num):\n",
    "            elem[\"url{}\".format(j + 1)] = items[i + j][0]\n",
    "            elem[\"s{}\".format(j + 1)] = items[i + j][3]\n",
    "            \n",
    "        writer.writerow(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas\n",
    "\n",
    "with open('v2_results.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "keys = [_[1] for _ in data]\n",
    "result = pandas.read_csv('results_v2_new.csv')\n",
    "filtered = result[result.AssignmentStatus==\"Approved\"]\n",
    "\n",
    "items = []\n",
    "for i, r in filtered.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "        \n",
    "    for i in range(1, num+1):\n",
    "        if r['Input.a{}'.format(i)] not in ['None', 'n/a'] and \" par \" not in r['Answer.d{}'.format(i)].lower() and r['Input.q{}'.format(i)] not in keys:\n",
    "            items.append((r['Input.url{}'.format(i)], r['Input.q{}'.format(i)], r['Input.a{}'.format(i)], r['Answer.d{}'.format(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "result = pandas.read_csv('results_v3.csv')\n",
    "\n",
    "filtered = result[result.AssignmentStatus==\"Approved\"]\n",
    "\n",
    "new_items = []\n",
    "for i, r in filtered.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for i in range(1, num + 1):\n",
    "        if r['Input.a{}'.format(i)] not in ['None', 'n/a'] and \" par \" not in str(r['Answer.d{}'.format(i)]).lower():\n",
    "            new_items.append((r['Input.url{}'.format(i)], r['Input.q{}'.format(i)], r['Input.a{}'.format(i)], r['Answer.d{}'.format(i)]))\n",
    "\n",
    "new_items = new_items + items\n",
    "\n",
    "with open('v3_results.json', 'w') as f:\n",
    "    json.dump(new_items, f, indent=2)\n",
    "    \n",
    "num = 5\n",
    "with open('v3_rewrite_input.csv', 'w') as f:\n",
    "    #json.dump(items, f, indent=2)\n",
    "    fields = []\n",
    "    for j in range(1, num + 1):\n",
    "        fields.append(\"url{}\".format(j))\n",
    "        fields.append(\"s{}\".format(j))\n",
    "        \n",
    "    writer = csv.DictWriter(f, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "    for i in range(0, len(new_items) - num, num):\n",
    "        elem = {}\n",
    "        for j in range(num):\n",
    "            elem[\"url{}\".format(j + 1)] = new_items[i + j][0]\n",
    "            elem[\"s{}\".format(j + 1)] = new_items[i + j][3]\n",
    "            \n",
    "        writer.writerow(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(new_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = \"\"\n",
    "for month, abb in [(\"January\", \"Jan\"), (\"February\", \"Feb\"), (\"March\", \"March\"), (\"April\", \"April\"), \n",
    "                   (\"May\", \"May\"), (\"June\",\"June\") , (\"July\", \"July\"), (\"August\", \"Aug\"), \n",
    "                   (\"September\", \"Sep\"), (\"October\", \"Oct\"), (\"November\", \"Nov\"), (\"December\", \"Dec\")]:\n",
    "    s += \";s/({})([1-9]+)/\\\\1 \\\\2/g;s/({}),([1-9]+)//g\".format(month, abb)\n",
    "print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import simplejson\n",
    "\n",
    "result = pandas.read_csv('v2_refine.csv')\n",
    "filtered_result = result[result.AssignmentStatus==\"Approved\"]\n",
    "\n",
    "items = []\n",
    "num = 10\n",
    "for i, r in filtered_result.iterrows():\n",
    "    for i in range(1, num+1):\n",
    "        items.append((r[\"Input.url{}\".format(i)],\"-\" ,\"-\" , r[\"Answer.d{}\".format(i)]))\n",
    "\n",
    "with open('v2_rewrite.json', 'w') as f:    \n",
    "    simplejson.dump(items, f, encoding='utf-8', ignore_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#import pandas\n",
    "import re\n",
    "import csv\n",
    "\n",
    "def dealwithNum(inp):\n",
    "    inp = re.sub(r\"([^0-9.])(0)([0-9])%\", r\"\\1\\2.\\3%\", inp)\n",
    "    \n",
    "    inp = re.sub(r\"([^0-9.])([1-9])([0-9])([0-9])%\", r\"\\1\\2\\3.\\4%\", inp)\n",
    "    inp = re.sub(r\"([^0-9.])(0)([0-9])([0-9])%\", r\"\\1\\2.\\3\\4%\", inp)\n",
    "    \n",
    "    inp = re.sub(r\"([^0-9.])([1-9])([0-9])([0-9])([0-9])%\", r\"\\1\\2\\3.\\4\\5%\", inp)\n",
    "    inp = re.sub(r\"([^0-9.])(0)([0-9])([0-9])([0-9])%\", r\"\\1\\2.\\3\\4\\5%\", inp)\n",
    "    \n",
    "    inp = re.sub(r\"10000%\", r\"100.00%\", inp)\n",
    "    inp = re.sub(r\"1000%\", r\"100.0%\", inp)\n",
    "    \n",
    "    inp = re.sub(r\"([^0-9.])([1-9])([0-9])([0-9])([0-9])([0-9])%\", r\"\\1\\2\\3.\\4\\5\\6%\", inp)\n",
    "    inp = re.sub(r\"([^0-9.])(0)([0-9])([0-9])([0-9])([0-9])%\", r\"\\1\\2.\\3\\4\\5\\6%\", inp)\n",
    "    \n",
    "    inp = re.sub(r\",([0-9])%\", r\".\\1%\", inp)\n",
    "    inp = re.sub(r\",([0-9])([0-9])%\", r\".\\1\\2%\", inp)\n",
    "    inp = re.sub(r\",([0-9])([0-9])([0-9])%\", r\".\\1\\2\\3%\", inp)\n",
    "    \n",
    "    \n",
    "    #inp = re.sub(r\"([0-9]),([0-9])\", r\"\\1\\2\", inp)\n",
    "    return inp\n",
    "\n",
    "\n",
    "with open('all_html.csv', 'w') as f:\n",
    "    fields = [\"url\", \"content\"]\n",
    "    writer = csv.DictWriter(f, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "    for f in os.listdir('WikiTableQuestions/wikidata/all_html/'):\n",
    "        with open('WikiTableQuestions/wikidata/all_html/' + f, 'r') as fr:\n",
    "            string = fr.readline().strip()\n",
    "        \n",
    "        writer.writerow({\"url\": f, \"content\": dealwithNum(string)})\n",
    "\n",
    "#inp_s = \"<td>123% <td> 0123% <td>012% <td>1233%  <td>12333% <td>10000% <td>01333%\"\n",
    "#dealwithNum(inp_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "table = pandas.read_csv('all_html.csv')\n",
    "\n",
    "for i, item in table.iterrows():\n",
    "    name = item['url']\n",
    "    content = item['content']\n",
    "    with open('WikiTableQuestions/wikidata/all_html/{}'.format(name), 'w') as f:\n",
    "        print >> f, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas\n",
    "\n",
    "result = pandas.read_csv('results_v4_1.csv')\n",
    "\n",
    "filtered = result[result.AssignmentStatus==\"Approved\"]\n",
    "\n",
    "items = []\n",
    "for i, r in filtered.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for i in range(1, num+1):\n",
    "        if r['Input.a{}'.format(i)] not in ['None', 'n/a'] and \" par \" not in r['Answer.d{}'.format(i)].lower():\n",
    "            items.append((r['Input.url{}'.format(i)], r['Input.q{}'.format(i)], r['Input.a{}'.format(i)], r['Answer.d{}'.format(i)]))\n",
    "\n",
    "with open('v4_1_results.json', 'w') as f:\n",
    "    json.dump(items, f, indent=2)\n",
    "\n",
    "num = 5\n",
    "with open('v4_rewrite_input.csv', 'w') as f:\n",
    "    #json.dump(items, f, indent=2)\n",
    "    fields = []\n",
    "    for j in range(1, num + 1):\n",
    "        fields.append(\"url{}\".format(j))\n",
    "        fields.append(\"s{}\".format(j))\n",
    "    \n",
    "    #fields.extend([\"url11\", \"s11\"])\n",
    "    \n",
    "    writer = csv.DictWriter(f, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "    for i in range(0, len(items) - num, num):\n",
    "        elem = {}\n",
    "        for j in range(num):\n",
    "            elem[\"url{}\".format(j + 1)] = items[i + j][0]\n",
    "            elem[\"s{}\".format(j + 1)] = items[i + j][3]\n",
    "        \n",
    "        #elem['url11'] = \"https://raw.githubusercontent.com/wenhuchen/Interface/master/WikiTableQuestions/wikidata/all_html/2-1236260-1.html\"\n",
    "        #elem['s11'] = \"Total is the rank of total\"\n",
    "            \n",
    "        writer.writerow(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import csv\n",
    "import json\n",
    "import simplejson\n",
    "\n",
    "r1 = pandas.read_csv('partial_refine_v2.csv')\n",
    "r2 = pandas.read_csv('partial_refine_v3.csv')\n",
    "r1 = r1[r1.AssignmentStatus==\"Approved\"]\n",
    "r2 = r2[r2.AssignmentStatus==\"Approved\"]\n",
    "\n",
    "results = {}\n",
    "finished = []\n",
    "for i, r in r1.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for j in range(1, num + 1):\n",
    "        html_name = r['Input.url{}'.format(j)].split('/')[-1]\n",
    "        t = r['Answer.d{}'.format(j)]\n",
    "        if t and isinstance(t, str) and t.lower() not in [\"na\", \"none\", \"n/a\", \"no\"]:\n",
    "            if html_name not in results:\n",
    "                results[html_name] = {\"text\": [], \"label\": []}\n",
    "            results[html_name]['text'].append(t)\n",
    "            results[html_name]['label'].append(1)\n",
    "        finished.append(r['Input.s{}'.format(j)])\n",
    "        \n",
    "for i, r in r2.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for j in range(1, num + 1):\n",
    "        html_name = r['Input.url{}'.format(j)].split('/')[-1]\n",
    "        t = r['Answer.d{}'.format(j)]\n",
    "        if t and isinstance(t, str) and t.lower() not in [\"na\", \"none\", \"n/a\", \"no\"]:\n",
    "            if html_name not in results:\n",
    "                results[html_name] = {\"text\": [], \"label\": []}        \n",
    "            results[html_name]['text'].append(r['Answer.d{}'.format(j)])\n",
    "            results[html_name]['label'].append(1)\n",
    "        finished.append(r['Input.s{}'.format(j)])\n",
    "\n",
    "r1 = pandas.read_csv('partial_neg_v2.csv')\n",
    "r2 = pandas.read_csv('partial_neg_v3.csv')\n",
    "r1 = r1[r1.AssignmentStatus==\"Approved\"]\n",
    "r2 = r2[r2.AssignmentStatus==\"Approved\"]\n",
    "\n",
    "for i, r in r1.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for j in range(1, num + 1):\n",
    "        t = r['Answer.d{}'.format(j)]\n",
    "        if t and isinstance(t, str) and t.lower() not in [\"na\", \"none\", \"n/a\", \"no\"]:\n",
    "            html_name = r['Input.url{}'.format(j)].split('/')[-1]\n",
    "            if html_name not in results:\n",
    "                results[html_name] = {\"text\": [], \"label\": []}\n",
    "            if r['Answer.d{}'.format(j)] not in results[html_name]['text']:\n",
    "                results[html_name]['text'].append(r['Answer.d{}'.format(j)])\n",
    "                results[html_name]['label'].append(-1)\n",
    "\n",
    "for i, r in r2.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for j in range(1, num + 1):\n",
    "        t = r['Answer.d{}'.format(j)]\n",
    "        if t and isinstance(t, str) and t.lower() not in [\"na\", \"none\", \"n/a\", \"no\"]:\n",
    "            html_name = r['Input.url{}'.format(j)].split('/')[-1]\n",
    "            if html_name not in results:\n",
    "                results[html_name] = {\"text\": [], \"label\": []}        \n",
    "            results[html_name]['text'].append(r['Answer.d{}'.format(j)])\n",
    "            results[html_name]['label'].append(-1)\n",
    "            \n",
    "with open('READY/prelim.json', 'w') as f:\n",
    "    simplejson.dump(results, f, encoding='utf-8', ignore_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare results\n",
    "inp_v2 = pandas.read_csv('v2_rewrite_input.csv')\n",
    "inp_v3 = pandas.read_csv('v3_rewrite_input.csv')\n",
    "\n",
    "not_finished = []\n",
    "done = 0\n",
    "for i, r in inp_v2.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for j in range(1, num + 1):\n",
    "        if r['s{}'.format(j)] not in finished:\n",
    "            not_finished.append((r['url{}'.format(j)], r['s{}'.format(j)]))\n",
    "        else:\n",
    "            done += 1\n",
    "        \n",
    "for i, r in inp_v3.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for j in range(1, num + 1):\n",
    "        if r['s{}'.format(j)] not in finished:\n",
    "            not_finished.append((r['url{}'.format(j)], r['s{}'.format(j)]))\n",
    "        else:\n",
    "            done += 1\n",
    "\n",
    "num = 5\n",
    "with open('v23_left_rewrite_input.csv', 'w') as f:\n",
    "    #json.dump(items, f, indent=2)\n",
    "    fields = []\n",
    "    for j in range(1, num + 1):\n",
    "        fields.append(\"url{}\".format(j))\n",
    "        fields.append(\"s{}\".format(j))\n",
    "    \n",
    "    #fields.extend([\"url11\", \"s11\"])\n",
    "    \n",
    "    writer = csv.DictWriter(f, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "    for i in range(0, len(not_finished) - num, num):\n",
    "        elem = {}\n",
    "        for j in range(num):\n",
    "            elem[\"url{}\".format(j + 1)] = not_finished[i + j][0]\n",
    "            elem[\"s{}\".format(j + 1)] = not_finished[i + j][1]\n",
    "        writer.writerow(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pandas.read_csv(\"input_file_yunkai.csv\")\n",
    "keys = set()\n",
    "for i, r in result.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for j in range(1, num + 1):\n",
    "        keys.add(r[\"url{}\".format(j)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pandas.read_csv(\"v4_rewrite_input.csv\")\n",
    "#keys = set()\n",
    "for i, r in result.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for j in range(1, num + 1):\n",
    "        if r[\"url{}\".format(j)] in keys:\n",
    "            keys.remove(r[\"url{}\".format(j)])\n",
    "unseen_tables = list(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('READY/prelim.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "pos = []\n",
    "neg = []\n",
    "pos_length = 0\n",
    "neg_length = 0\n",
    "for k in data:\n",
    "    text = data[k]['text']\n",
    "    label = data[k]['label']\n",
    "    for t, l in zip(text, label):\n",
    "        if l == 1:\n",
    "            pos.append(t)\n",
    "            pos_length += len(t.split())\n",
    "        else:\n",
    "            neg.append(t)\n",
    "            neg_length += len(t.split())\n",
    "\n",
    "print len(pos), len(neg)\n",
    "print (pos_length + 0.0) / len(pos)\n",
    "print (neg_length + 0.0) / len(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "a = Counter()\n",
    "a.update([1,2,3])\n",
    "a.update([1,3,4])\n",
    "\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import csv\n",
    "\n",
    "r1 = pandas.read_csv('/Users/wenhuchen/Downloads/Batch_3580679_batch_results.csv')\n",
    "r2 = pandas.read_csv('/Users/wenhuchen/Downloads/Batch_3584639_batch_results.csv')\n",
    "r1 = r1[r1.AssignmentStatus==\"Approved\"]\n",
    "r2 = r2[r2.AssignmentStatus==\"Approved\"]\n",
    "\n",
    "r3 = pandas.concat([r1, r2])\n",
    "finished = []\n",
    "\n",
    "r1_inp = pandas.read_csv('v23_left_rewrite_input.csv')\n",
    "r2_inp = pandas.read_csv('v4_rewrite_input.csv')\n",
    "r3_inp = pandas.concat([r1_inp, r2_inp])\n",
    "\n",
    "for i, r in r3.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for j in range(1, num + 1):\n",
    "        #if r[\"url{}\".format(j)] in keys:\n",
    "        finished.append(r[\"Input.s{}\".format(j)])\n",
    "\n",
    "print len(finished)\n",
    "unfinished = []\n",
    "done = 0\n",
    "finished_old = []\n",
    "for i,r in r3_inp.iterrows():\n",
    "    if \"url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for j in range(1, num + 1):\n",
    "        #if r[\"url{}\".format(j)] in keys:\n",
    "        if r[\"s{}\".format(j)]  not in finished:\n",
    "            unfinished.append((r[\"url{}\".format(j)], r[\"s{}\".format(j)]))\n",
    "        else:\n",
    "            finished_old.append(r[\"s{}\".format(j)])\n",
    "            done += 1\n",
    "\n",
    "print done\n",
    "with open('v234_rest_rewrite_input.csv', 'w') as f:\n",
    "    #json.dump(items, f, indent=2)\n",
    "    num = 5\n",
    "    fields = []\n",
    "    for j in range(1, num + 1):\n",
    "        fields.append(\"url{}\".format(j))\n",
    "        fields.append(\"s{}\".format(j))\n",
    "        \n",
    "    writer = csv.DictWriter(f, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "    for i in range(0, len(unfinished) - num, num):\n",
    "        elem = {}\n",
    "        for j in range(num):\n",
    "            elem[\"url{}\".format(j + 1)] = unfinished[i + j][0]\n",
    "            elem[\"s{}\".format(j + 1)] = unfinished[i + j][1]\n",
    "            \n",
    "        writer.writerow(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r1 = pandas.read_csv('/Users/wenhuchen/Downloads/Batch_3583922_batch_results.csv')\n",
    "r2 = pandas.read_csv('/Users/wenhuchen/Downloads/Batch_3579309_batch_results.csv')\n",
    "r3 = pandas.read_csv('/Users/wenhuchen/Downloads/Batch_3579785_batch_results.csv')\n",
    "\n",
    "r1 = r1[r1.AssignmentStatus==\"Approved\"]\n",
    "r2 = r2[r2.AssignmentStatus==\"Approved\"]\n",
    "r3 = r3[r3.AssignmentStatus==\"Approved\"]\n",
    "\n",
    "r4 = pandas.concat([r1, r2, r3])\n",
    "finished = []\n",
    "\n",
    "\n",
    "for i, r in r4.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for j in range(1, num + 1):\n",
    "        finished.append(r[\"Input.s{}\".format(j)])\n",
    "print len(finished)\n",
    "\n",
    "r1_inp = pandas.read_csv('v2_rewrite_input.csv')\n",
    "r2_inp = pandas.read_csv('v3_rewrite_input.csv')\n",
    "r3_inp = pandas.read_csv('v4_rewrite_input.csv')\n",
    "r4_inp = pandas.concat([r1_inp, r2_inp, r3_inp])\n",
    "unfinished = []\n",
    "done = 0\n",
    "for i,r in r4_inp.iterrows():\n",
    "    if \"url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for j in range(1, num + 1):\n",
    "        #if r[\"url{}\".format(j)] in keys:\n",
    "        if r[\"s{}\".format(j)]  not in finished:\n",
    "            unfinished.append((r[\"url{}\".format(j)], r[\"s{}\".format(j)]))\n",
    "        else:\n",
    "            done += 1\n",
    "\n",
    "print done\n",
    "with open('v234_rest_rewrite_fake_input.csv', 'w') as f:\n",
    "    num = 5\n",
    "    fields = []\n",
    "    for j in range(1, num + 1):\n",
    "        fields.append(\"url{}\".format(j))\n",
    "        fields.append(\"s{}\".format(j))\n",
    "        \n",
    "    writer = csv.DictWriter(f, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "    for i in range(0, len(unfinished) - num, num):\n",
    "        elem = {}\n",
    "        for j in range(num):\n",
    "            elem[\"url{}\".format(j + 1)] = unfinished[i + j][0]\n",
    "            elem[\"s{}\".format(j + 1)] = unfinished[i + j][1]\n",
    "            \n",
    "        writer.writerow(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def substitute(string):\n",
    "    string = string.lower()\n",
    "    \n",
    "    string = string.replace(r\"\\n\", \"\")\n",
    "    string = string.replace(r\"\\\\\", \"\")\n",
    "    string = string.replace(r\"!$\", \"\")\n",
    "    string = string.replace(r\"#\", \"\")\n",
    "    string = string.replace('–', '-')\n",
    "    string = string.replace('−', '-')\n",
    "    string = string.replace('−', '-')\n",
    "    string = string.replace('â', '')\n",
    "    string = string.replace('“', '')\n",
    "    string = string.replace('€', '')    \n",
    "    string = string.replace(\"√\", \"\")\n",
    "    string = string.replace(r'\"', '')\n",
    "    string = string.replace(r'\\.0 ', '')\n",
    "    string = string.replace(r'¹', '')\n",
    "    string = string.replace(r'‡', '')\n",
    "    string = string.replace(r'«', '')\n",
    "    string = string.replace(r'»', '')\n",
    "    \n",
    "    string = string.replace(r\"'s\", \" 's\")\n",
    "    string = string.replace(r\"'re\", \" 're\")\n",
    "    string = string.replace(r\"'nt\", \" not\")\n",
    "    string = string.replace(r'@', ' ')\n",
    "    string = string.replace(r'`', '')\n",
    "    string = string.replace(r'•', ' ')\n",
    "    string = string.replace(r'·', ' ')\n",
    "    string = string.replace(r'²', ' square')\n",
    "    string = string.replace(r'\\[', '')\n",
    "    string = string.replace(r'\\]', '')\n",
    "    string = string.replace(r'\\{', '')\n",
    "    string = string.replace(r'\\}', '')\n",
    "    string = string.replace(r'\\|', '')\n",
    "    string = string.replace(r'\\^', '')\n",
    "    string = string.replace(r'”', '')\n",
    "\n",
    "    string = re.sub(r'\\[.+\\]', ' ', string)\n",
    "    string = re.sub(r',([0-9]{3})(?![0-9])', r'\\1', string)\n",
    "    #string = re.sub(r'([0-9]{1-3}),([0-9]{3}),([0-9]{3})([^0-9])', r\"\\1\\2\\3\\4\", string)\n",
    "    #string = re.sub(r'([0-9]{1-3}),([0-9]{3}),([0-9]{3}),([0-9]{3})([^0-9])', r\"\\1\\2\\3\\4\\5\", string)\n",
    "    #string = re.sub(r'([0-9]{1-3}),([0-9]{3}),([0-9]{3}),([0-9]{3}),([0-9]{3})([^0-9])', r\"\\1\\2\\3\\4\\5\\6\", string)\n",
    "\n",
    "    string = re.sub(r'([^,]),', r\"\\1 ,\", string)\n",
    "    string = re.sub(r',([^,])', r\", \\1\", string)\n",
    "    string = re.sub(r'([^(])\\(', r\"\\1 (\", string)\n",
    "    string = re.sub(r'\\)([^)])', r\") \\1\", string)\n",
    "    string = re.sub(r'\\.\\)', r\")\", string)\n",
    "    string = re.sub(r'([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)=', r\"\\1+\\2+\\3+\\4=\", string)\n",
    "    string = re.sub(r'([0-9]+)-([0-9]+)-([0-9]+)=', r\"\\1+\\2+\\3=\", string)\n",
    "    string = re.sub(r'([0-9]+)-([0-9]+)=', r\"\\1+\\2=\", string)\n",
    "    string = re.sub(r\"' +([0-9])\", r\"'\\1\", string)\n",
    "\n",
    "    string = re.sub(r\"([^ ])\\+\", r\"\\1 +\", string)\n",
    "    string = re.sub(r\"\\+([^ ])\", r\"+ \\1\", string)\n",
    "    string = re.sub(r\"([^ ])=\", r\"\\1 =\", string)\n",
    "    string = re.sub(r\"=([^ ])\", r\"= \\1\", string)\n",
    "\n",
    "    string = re.sub(r\"-([^- ])\", r\"- \\1\", string)\n",
    "    string = re.sub(r\"([^- ])-\", r\"\\1 -\", string)\n",
    "    string = re.sub(r\"-([^- ])\", r\"- \\1\", string)\n",
    "    string = re.sub(r\"/([^ ])\", r\"/ \\1\", string)\n",
    "    string = re.sub(r\"([^ ])/\", r\"\\1 /\", string)\n",
    "    string = string.replace(r'()', '')\n",
    "    \n",
    "    string = re.sub(r'([^0-9 ]):', r\"\\1 :\", string)\n",
    "    string = re.sub(r':([^0-9 ])', r\": \\1\", string)\n",
    "    string = re.sub(r'([0-9])pm', r\"\\1 pm\", string)\n",
    "    string = re.sub(r'([0-9])am', r\"\\1 am\", string)\n",
    "    string = re.sub(r'([0-9])rpm', r\"\\1 rpm\", string)\n",
    "    string = re.sub(r'([0-9])km', r\"\\1 km\", string)\n",
    "    string = re.sub(r'([0-9])cm', r\"\\1 cm\", string)\n",
    "    string = re.sub(r'([0-9])m', r\"\\1 m\", string)\n",
    "    string = re.sub(r'([0-9])mm', r\"\\1 mm\", string)\n",
    "    string = re.sub(r'([0-9])kg', r\"\\1 kg\", string)\n",
    "    string = re.sub(r'([0-9])g', r\"\\1 g\", string)\n",
    "    string = re.sub(r'([0-9])kw', r\"\\1 kw\", string)\n",
    "    string = re.sub(r'([0-9])kv', r\"\\1 kv\", string)\n",
    "    string = re.sub(r'([0-9])mph', r\"\\1 mph\", string)\n",
    "    #string = re.sub(r'([0-9])@', r\"\\1 @\", string)\n",
    "    #string = re.sub(r'@([0-9])', r\"@ \\1\", string)\n",
    "    string = re.sub(r'category : articles with hcards', r\"\", string)\n",
    "    string = re.sub(r'category : articles with hcard', r\"\", string)\n",
    "    string = re.sub(r'category : articles without hcard', r\"\", string)\n",
    "    \n",
    "    string = re.sub(r\"\\.+$\", '', string)\n",
    "    string = re.sub(r',+$', '', string)    \n",
    "    string = re.sub(r'\\s+', ' ', string)\n",
    "    string = re.sub(r'\\.+','.',string)\n",
    "    string = re.sub(r',+',',',string)\n",
    "    string = re.sub(r'^ ', '', string)\n",
    "    string = re.sub(r' $', '', string)\n",
    "    string = re.sub('70 - 76 - 68 - 214', '70 + 76 + 68 = 214', string)\n",
    "    return string\n",
    "\n",
    "#print substitute(\"fa\\g##ga,/// she got(ff)ff...\")\n",
    "#print substitute('(5) fa:\"12-12-13=31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blacklist(string):\n",
    "    black = ['bye', \"no chart for\", \"km (mi)\", \"lb·ft\", \"ft (m)\", \"kg (lb)\", \n",
    "             \"a report of report\", \"report was report\", \"is 'report'\", \"?\"]\n",
    "    for b in black:\n",
    "        if b in string:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "with open('data/short_subset.txt') as f:\n",
    "    limit_length = [_.strip() for _ in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import sys\n",
    "import pandas\n",
    "\n",
    "r1_1 = pandas.read_csv(\"/Users/wenhuchen/Downloads/harvest/refine_0.csv\")\n",
    "r1_2 = pandas.read_csv(\"/Users/wenhuchen/Downloads/harvest/refine_1.csv\")\n",
    "\n",
    "r1 = pandas.concat([r1_1, r1_2])\n",
    "r1 = r1[r1.AssignmentStatus==\"Approved\"]\n",
    "\n",
    "f = open('/tmp/output.txt', 'w')\n",
    "\n",
    "index = 0\n",
    "finished = {}\n",
    "trash = []\n",
    "for i,r in r1.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for j in range(1, num + 1):\n",
    "        orig_input = r[\"Answer.d{}\".format(j)]\n",
    "        html_name = r['Input.url{}'.format(j)].split('/')[-1] + '.csv'\n",
    "        if html_name not in limit_length:\n",
    "            continue\n",
    "        if isinstance(orig_input, str) and orig_input.lower() in [\"na\", \"n/a\", \"no\"]:\n",
    "            #trash.append(html_name)\n",
    "            print \"error\"\n",
    "        if isinstance(orig_input, str) and len(orig_input.split(' ')) > 3 and not blacklist(orig_input):\n",
    "            replaced_sent = substitute(orig_input)\n",
    "            if 'hcard' not in replaced_sent:\n",
    "                print >> f, replaced_sent\n",
    "                index += 1\n",
    "                if html_name not in finished:\n",
    "                    finished[html_name] = [[replaced_sent], [1]]\n",
    "                else:\n",
    "                    finished[html_name][0].append(replaced_sent)\n",
    "                    finished[html_name][1].append(1)\n",
    "                    \n",
    "r2_1 = pandas.read_csv(\"/Users/wenhuchen/Downloads/harvest/refine_2.csv\")\n",
    "r2_2 = pandas.read_csv(\"/Users/wenhuchen/Downloads/harvest/refine_3.csv\")\n",
    "r2_3 = pandas.read_csv(\"/Users/wenhuchen/Downloads/harvest/refine_4.csv\")\n",
    "\n",
    "r2 = pandas.concat([r2_1, r2_2, r2_3])\n",
    "r2 = r2[r2.AssignmentStatus==\"Approved\"]\n",
    "\n",
    "for i,r in r2.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for j in range(1, num + 1):\n",
    "        orig_input = r[\"Answer.d{}\".format(j)]\n",
    "        html_name = r['Input.url{}'.format(j)].split('/')[-1] + '.csv'\n",
    "        if html_name not in limit_length:\n",
    "            continue     \n",
    "        if isinstance(orig_input, str) and orig_input.lower() in [\"na\", \"n/a\", \"no\"]:\n",
    "            print \"error\"\n",
    "        if isinstance(orig_input, str) and len(orig_input.split(' ')) > 3 and not blacklist(orig_input):\n",
    "            replaced_sent = substitute(orig_input)\n",
    "            if 'hcard' not in replaced_sent:\n",
    "                print >> f, replaced_sent\n",
    "                index += 1\n",
    "                if html_name not in finished:\n",
    "                    finished[html_name] = [[replaced_sent], [1]]\n",
    "                else:\n",
    "                    finished[html_name][0].append(replaced_sent)\n",
    "                    finished[html_name][1].append(1)\n",
    "\n",
    "\n",
    "r3_1 = pandas.read_csv(\"/Users/wenhuchen/Downloads/harvest/fake_0.csv\")\n",
    "r3_2 = pandas.read_csv(\"/Users/wenhuchen/Downloads/harvest/fake_1.csv\")\n",
    "r3_3 = pandas.read_csv(\"/Users/wenhuchen/Downloads/harvest/fake_2.csv\")\n",
    "r3_4 = pandas.read_csv(\"/Users/wenhuchen/Downloads/harvest/fake_3.csv\")\n",
    "\n",
    "r3 = pandas.concat([r3_1, r3_2, r3_3, r3_4])\n",
    "r3 = r3[r3.AssignmentStatus==\"Approved\"]\n",
    "\n",
    "f = open('/tmp/output.txt', 'w')\n",
    "\n",
    "index = 0\n",
    "for i,r in r3.iterrows():\n",
    "    if \"Input.url10\" in r:\n",
    "        num = 10\n",
    "    else:\n",
    "        num = 5\n",
    "    for j in range(1, num + 1):\n",
    "        orig_input = r[\"Answer.d{}\".format(j)]\n",
    "        html_name = r['Input.url{}'.format(j)].split('/')[-1] + '.csv'\n",
    "        if html_name not in limit_length:\n",
    "            continue\n",
    "        if isinstance(orig_input, str) and orig_input.lower() in [\"na\", \"n/a\", \"no\"]:\n",
    "            print \"error\"\n",
    "        if isinstance(orig_input, str) and len(orig_input.split(' ')) > 3 and not blacklist(orig_input):\n",
    "            replaced_sent = substitute(orig_input)\n",
    "            if 'hcard' not in replaced_sent:\n",
    "                print >> f, replaced_sent\n",
    "                index += 1\n",
    "                if html_name not in finished:\n",
    "                    finished[html_name] = [[replaced_sent], [0]]\n",
    "                else:\n",
    "                    finished[html_name][0].append(replaced_sent)\n",
    "                    finished[html_name][1].append(0)\n",
    "\n",
    "f.close()\n",
    "print index\n",
    "import json\n",
    "with open(\"READY/training_all.json\", 'w') as f:\n",
    "    json.dump(finished, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print trash\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print trash\n",
    "for l in trash + [\"2-11916083-12.html\", \"2-1236260-1.html\"]:\n",
    "    try:\n",
    "        shutil.move(\"data/all_csv/\" + l + \".csv\", \"data/trash_csv/\" + l + \".csv\")\n",
    "    except Exception:\n",
    "        print \"error, {}\".format(\"data/all_csv/\" + l + \".csv\", \"data/trash_csv/\" + l + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import csv\n",
    "\n",
    "url = open('WikiTableQuestions/wikidata/all_html/2-18178551-5.html').readline().strip()\n",
    "soup = BeautifulSoup(url, \"html.parser\")\n",
    "\n",
    "table = soup.findAll(\"table\", {\"class\":\"wikitable\"})[0]\n",
    "rows = table.findAll(\"tr\")\n",
    "\n",
    "with open('/tmp/editors.csv', \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in rows:\n",
    "        csv_row = []\n",
    "        for cell in row.findAll([\"td\", \"th\"]):\n",
    "            csv_row.append(cell.get_text())\n",
    "        writer.writerow(csv_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "import csv\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "for filename in os.listdir('WikiTableQuestions/wikidata/all_html/'):\n",
    "    if filename.endswith(\".html\"):\n",
    "        url = open('WikiTableQuestions/wikidata/all_html/' + filename).readline().strip()\n",
    "        soup = BeautifulSoup(url, \"html.parser\")\n",
    "        table = soup.findAll(\"table\", {\"class\":\"wikitable\"})\n",
    "        if len(table) > 0:\n",
    "            table = table[0]\n",
    "            rows = table.findAll(\"tr\")\n",
    "            with open('WikiTableQuestions/wikidata/all_csv/' + filename + '.csv', 'w') as csvfile:\n",
    "                spamwriter = csv.writer(csvfile, delimiter='#')\n",
    "                for row in rows:\n",
    "                    csv_row = []\n",
    "                    for cell in row.findAll([\"td\", \"th\"]):\n",
    "                        print cell.get_text()\n",
    "                        csv_row.append(substitute(cell.get_text()))\n",
    "                        print substitute(cell.get_text())\n",
    "                        print \"\"\n",
    "                    spamwriter.writerow(csv_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "import csv\n",
    "import urllib\n",
    "import json\n",
    "import os\n",
    "\n",
    "with open('READY/training_all.json') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "files = data.keys()\n",
    "\n",
    "unseen = []\n",
    "with open('data/short_subset.txt') as fs:\n",
    "    for f in fs:\n",
    "        f = f.strip()\n",
    "        if f not in files and f in tiny_mapping:\n",
    "            unseen.append(f)\n",
    "with open(\"data/v5_unseen.json\", 'w') as f:\n",
    "    json.dump(unseen, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "import json\n",
    "import urllib\n",
    "import json\n",
    "import os \n",
    "import csv\n",
    "\n",
    "with open('data/table_to_page_new.json', 'r') as f:\n",
    "    tiny_mapping = json.load(f)\n",
    "    \n",
    "with open(\"data/v5_unseen.json\", 'r') as f:\n",
    "    unseen = json.load(f)\n",
    "    \n",
    "with open('v5_write_input.csv', 'w') as f:\n",
    "    fields = [\"url1\", \"wiki1\", \"topic1\"]\n",
    "    writer = csv.DictWriter(f, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for k in unseen:\n",
    "        if k in tiny_mapping:\n",
    "            writer.writerow({\"url1\": 'https://raw.githubusercontent.com/wenhuchen/Table-Fact-Checking/master/data/all_csv/' + k, \n",
    "                            \"wiki1\": tiny_mapping[k][1], \"topic1\": tiny_mapping[k][0]})\n",
    "        else:\n",
    "            writer.writerow({\"url1\": 'https://raw.githubusercontent.com/wenhuchen/Table-Fact-Checking/master/data/all_csv/' + k, \"wiki1\": \"javascript:void(0)\", \"topic1\": \"None\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/tmp/table_to_page.json', 'r') as f:\n",
    "    old_tiny_mapping1 = json.load(f)\n",
    "with open('data/table_to_page.json', 'r') as f:\n",
    "    old_tiny_mapping2 = json.load(f)\n",
    "    \n",
    "new_tiny_mapping = {}\n",
    "for k, v in old_tiny_mapping2.iteritems():\n",
    "    new_tiny_mapping[k] = [substitute(old_tiny_mapping1[k].split('/')[-1].replace('_', ' ')), old_tiny_mapping2[k]]\n",
    "\n",
    "with open('data/table_to_page_new.json', 'w') as f:\n",
    "    json.dump(new_tiny_mapping, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/tmp/g.txt', 'w') as f:\n",
    "    x = \"https://en.wikipedia.org/wiki/2007%E2%80%9308_Scottish_Second_Division\"\n",
    "    print >> f, [\"topic\", urllib.unquote(x).split('/')[-1]]\n",
    "    x = 'https://en.wikipedia.org/wiki/Ana_Timoti%C4%87'\n",
    "    print >> f, {\"topic\": urllib.unquote(x).split('/')[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "name = files[0]\n",
    "tab = pandas.read_csv('data/all_csv/' + name + '.csv', delimiter='#')\n",
    "sent = data[name][0][0]\n",
    "label = data[name][1][0]\n",
    "\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print sent, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "activations = []\n",
    "for i, t in enumerate(tab.columns):\n",
    "    for j, v in enumerate(tab[t]):\n",
    "        if isinstance(v, str) and len(v.split(' ')) > 2:\n",
    "            if fuzz.partial_ratio(v, sent) > 95:\n",
    "                print t, j\n",
    "        else:\n",
    "            if str(v) in sent:\n",
    "                print t, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa = 0.505406867561\n",
      "Counter({'Entailed': 762, 'Contradictory': 650, 'Problematic': 63, 'Neutral': 40})\n",
      "('2-14347546-5.html.csv', 'the record for the december under 28 with a game under 26 with less than 38 points and a score of 0 - 1 in ot is 12 - 6 - 6 - 1')\n",
      "['Contradictory', 'Entailed', 'Neutral']\n",
      "('2-17162128-3.html.csv', 'the united states is the country when to par is + 11 when the total is more than 151')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('1-21781578-2.html.csv', 'the original air date for season 2 was january 13 , 2002')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-16387653-1.html.csv', 'during the st. kilda and fitzroy game the crowd size was 12656')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('1-14319023-2.html.csv', 'in 2009 , the mixed double consists of didit juang indrianto and yayu rahayu and hermansyah is the boys singles')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-176524-1.html.csv', 'drummond village is 8.91 in area')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('2-12259758-6.html.csv', 'the score in the final on june 22 , 2013 on clay was 4 - 6 , 4 - 6')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('2-12536586-1.html.csv', 'the week 14 game against the buffalo bills reported the second highest attendance of the season')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-1204998-2.html.csv', 'w\\xc7\\x94p\\xc3\\xadng xi\\xc3\\xa0n is the pinyin for the traditional chinese name \\xe6\\xad\\xa6\\xe5\\xb9\\xb3\\xe7\\xb8\\xa3')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('2-12207449-6.html.csv', 'white sox recorded 63 - 56 on august 12')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-10953197-4.html.csv', 'dee johnson was the writer for the episode with production codes 2395096 & 2395877')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-1028356-3.html.csv', 'the score of the match was 6 - 1 , 7 - 6 (3) with the opponents of anne hobbs and andrew castle')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-11611293-10.html.csv', 'jp maher had a date of 19 - 02 - 2003')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-23696862-6.html.csv', 'andras koroknai had 2 wsop cashes and was 4rth in final place')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-1204998-2.html.csv', 'shanghang county has an area of 3099')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-14269540-5.html.csv', 'it was before may 21 when snell (2 - 3) received the loss for the game and has a 22 - 24 record')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-1028356-3.html.csv', 'the wimbledon (2) championship was played in 1988')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-11548185-5.html.csv', 'the lowest episode number with an air date of october 31 2001 , is episode 83')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-2849652-2.html.csv', 'in 1978 there was 1 winter season with exactly 1 division')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-11872185-5.html.csv', 'the studio red chillies entertainment has two films in the top ten list')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('1-10953197-4.html.csv', 'one is the total number of episodes with the production code 2395120')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('2-16965329-5.html.csv', 'the guayaquil tournament was played on 5 november 2007 with a score of 3 - 6 , 7 - 6 (6) , 4 - 7')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('1-13619053-9.html.csv', 'indiana was the team in a game with a record less than 15 - 63')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-26593762-3.html.csv', 'the table position for the team whose outgoing manager was andy thorn was 9th')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-17162128-3.html.csv', 'hale irwin is the only player from the united states to win multiple years')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-11780179-1.html.csv', 'kazakhstan is the country which gdp (nominal) of $6.4 billion and has a population greater than 5550239')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-11780179-1.html.csv', 'turkmenistan has a population is less than 5550239 and gdp (nominal) greater than $6.4 billion')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('2-176524-1.html.csv', '18.06 is the area in the census of the community ranked 636 of 5008')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('2-14344187-13.html.csv', 'matt brait was later than the 11th round')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('2-1478772-2.html.csv', '77:54 minutes was the length of the game that was played with the new york jets at home')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-17301013-5.html.csv', 'when st. louis is the visitor , the record is between 12 - 28 - 5 and 16 - 24 - 5')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-14344187-13.html.csv', 'greg johnson is from sweden')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-2509350-3.html.csv', 'the quechua language in el villar is the highest in the municipality')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('2-11870943-8.html.csv', 'the us open had a 2r categorization between 2010 and 2012 and an sf categorization between 2007 and 2009')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-15532127-1.html.csv', 'the scores were 1 - 0 , 3 - 0 , and 4 - 0 in competitions with a result of 5 - 0 at the 1996 afc asian cup qualification')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('2-12552861-1.html.csv', \"tan joe hok won the men 's singles and robert b. williams ethel marshall won the mixed doubles in 1957\")\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-10953197-4.html.csv', 'kimberly costello is the writer for the episodes with a production codes 2395114 and 2395115')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-14319023-2.html.csv', 'in 2010 , when mixed doubles is danny bawa chrisnanta and debby susanto , the boys singles is nugroho andi saputro')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-26593762-3.html.csv', \"brial laws' team acquired a position higher than 9th\")\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-10287593-1.html.csv', '5 is the average number of fixtures when 2 clubs are involved')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-15532127-1.html.csv', 'the 1996 afc asian cup qualification is the competition with a score of 4 - 0 and result of 5 - 0 on june 22nd , 1997')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('1-28081876-4.html.csv', 'season 6 , series number 11 was directed by rob schrab and was writteh by one person')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-16387653-1.html.csv', 'when footscray played richmond at home they scored 75')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('2-1478772-2.html.csv', 'the oakland raiders were the home team for the game played on december 24 , 1977')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('2-10883333-13.html.csv', 'footscray was the away team when north melbourne was the home team')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-10696381-1.html.csv', 'dave nugent played defensive tackle')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-10953197-4.html.csv', 'kimberly costello wrote all the episodes till production code 2395114')\n",
      "['Contradictory', 'Contradictory', 'Neutral']\n",
      "('2-1717109-6.html.csv', 'in 1983 , 87 , and 88 tournament results followed a / 1r / a')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('1-261927-1.html.csv', 'the location for the colors green & black is less than 10235')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-16387653-1.html.csv', 'when playing against carlton , collingwood was the away team')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('1-2509350-3.html.csv', 'the language for villa 1167 is spanish')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-16013858-11.html.csv', 'set 2 was 25 - 20 when set 3 was 22 - 25')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-1717109-6.html.csv', 'in 1989 the result for the tournament at indian wells was qf')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-12805568-1.html.csv', 'construction started on 01.06.1964 for the vver - 365 (prototype) with a net capacity of 197 mw and was shutdown on 29.08.1990')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('2-17358229-1.html.csv', 'european race walking cup has a higher position than 2nd in the competition')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-23696862-6.html.csv', 'the person who had $39371 wsop earnings had three wsop cashes')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('1-27437601-2.html.csv', 'may 5 , 2011 is the 1st air date for season 12')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-12259758-6.html.csv', 'micha\\xc3\\xabl llodra nenad zimonji\\xc4\\x87 was the partner for outcome of runner - up and date of august 7 , 2011')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-14347546-5.html.csv', 'there were 38.0 points in the game over 25 whose opponent was the buffalo sabres')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-29728787-1.html.csv', 'wolfgang sawallische was the count when dietrich fischer dieskau was the conductor')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-1122578-1.html.csv', 'the grid for denny hulme is over 6.0')\n",
      "['Contradictory', 'Contradictory', 'Neutral']\n",
      "('2-10883333-13.html.csv', 'fitzroy was the home team when the away team was south melbourne')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-1234504-1.html.csv', 'wheel arrangement 4 - 4 - 0 , has baldwin as builder')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('1-16387653-1.html.csv', 'carlton beat collingwood by a score of 109 - 82')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('1-14986292-1.html.csv', 'the population density for duque de caxias in 2010 was more than 1840')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('2-16013858-11.html.csv', 'on june 26 set 1 was 21 - 19 when set 3 was 26 - 24')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-14344187-13.html.csv', 'in round 3 , the player in the center position was reid simpson')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-17301013-5.html.csv', 'record st. louis the visitor is 26 - 5 - 14')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-12259758-6.html.csv', 'the score was 4 - 6 , 4 - 6 in the final for the event right after january 12 , 2013')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('1-29728787-1.html.csv', 'karl bohm is the count when hermann uhde was the conductor')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('2-12036377-1.html.csv', 'napoli - roma first match of the serie a was on 30 january 1938')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('1-26593762-3.html.csv', 'dougie freedman was the incoming manager for the team that darren ferguson served as outgoing manager for')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-1478772-2.html.csv', 'the game against the baltimore colts was 82:40 long')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-14986292-1.html.csv', 'japeri had a population more than 95391')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('2-16678300-2.html.csv', 'week 10 took place on november 6 , 1977')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-17162128-3.html.csv', 'steve jones is the only player from the united states and the only play with a total of 154')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-21781578-2.html.csv', 'the season number with the highest u.s. viewers (millions) was season no. 13 with 13.00')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('1-10953197-4.html.csv', 'episode melrose unguled is numbered 124.0')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-12036377-1.html.csv', 'the result of the roma - napoli match was 1 - 1 / 3 - 0 / 1 - 0 / 1 - 2 / 1 - 2 / 3 - 2 / 1 - 2 / 0 - 0 / 2 - 2 / 1 - 0 / 0 - 1 / 2 - 1 / 1 - 1 / 2 - 1 / 0 - 3 / 1 - 2 / 0 - 0 / 0 - 0 / 1 - 0 / 2 - 0 / 1 - 1 / 1 - 2 / 0 - 0 / 3 - 0 / 1 - 0 / 3 - 2 / 3 - 3 / 1 - 0 / 2 - 0 / 2 - 0 / 0 - 0 / 0 - 0 / 1 - 2')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('1-13619053-9.html.csv', 'milwaukee was the team that played after april 1')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('2-11753791-1.html.csv', 'a team that has a more wins than losses has 0 ties')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('2-10883333-13.html.csv', 'essendon was the away team when collingwood played as the home team')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('1-1341640-14.html.csv', 'paul findley , district illinois 20 , was first elected after henry hyde , district illinois 6')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('2-11780179-1.html.csv', 'the country that has a gdp per capita (nominal) of $29.9 billion is tajikistan')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-12552861-1.html.csv', \"tan joe hok won the men 's singles in 1958\")\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-1204998-2.html.csv', 'when hakka is zh\\xc4\\x81ngp\\xc3\\xadng sh\\xc3\\xac the area is 2879')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-23696862-6.html.csv', 'jesse sylvia had 0 wsop earnings')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('2-10696381-1.html.csv', 'dave stachelski was picked before the 5th round')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-1076869-2.html.csv', 'the bb cw for 1963 is 22 / and the riaa is g')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-18223552-1.html.csv', 'the match 31 july 1993 with result of 0 - 1 against kaizer chiefs had 65000 people')\n",
      "['Contradictory', 'Neutral', 'Contradictory']\n",
      "('1-261927-1.html.csv', 'more than one institution have the colors blue and gold')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('1-1341640-14.html.csv', 'in 1974 republican phil crane beat henry hyde who was a democrat')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('1-26211058-1.html.csv', 'when the specimen weight / size is 1000 g / 8.79 cm , the estimated exposure (mrem) / hr* is 0.00')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-27821519-1.html.csv', 'toyota is the manufacturer of no. 50')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-20626467-1.html.csv', 'the jockey for group 1 at the 1400 m distance at randwick was hugh bowman , with a result of 1st')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('2-12206211-4.html.csv', 'the score in the date of june 7 was 12 - 3')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-17327458-1.html.csv', 'more than two vacancies happened on may 25')\n",
      "['Contradictory', 'Neutral', 'Contradictory']\n",
      "('2-1234504-1.html.csv', 'mason built the order on november 1881 of more than 54 tc&stl no. (1883 - 84)')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-21781578-2.html.csv', 'john david coles had 5 episodes that were written by him and that were also directed by him')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-23696862-6.html.csv', 'the person who had 0 wsop earnings had five wsop cashes')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-17301013-5.html.csv', 'the home team on january 2 , which had 23 points , is buffalo')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-1028356-3.html.csv', 'with jim pugh as partner , the score of the match was 7 - 5 , 6 - 2')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-17327458-1.html.csv', 'mixu paatelainen was suspended on may 29th')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-261927-1.html.csv', 'the colors of massachusetts institute of technology (mit) are green and black')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-24055352-1.html.csv', \"d'andre bell is the last player from los angeles\")\n",
      "['Contradictory', 'Neutral', 'Neutral']\n",
      "('2-17162128-3.html.csv', 'steve jones was the player when the total is more than 154')\n",
      "['Contradictory', 'Contradictory', 'Neutral']\n",
      "('2-1234504-1.html.csv', 'porter built the order on november 1881 of less than 54 tc&stl')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-12552861-1.html.csv', \"when erland kops won the men 's singles in 1958 , jean miller won the women 's singles\")\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-14319023-2.html.csv', 'in 2010 , the girls doubles were ayu pratiwi and anggi widia and the boys doubles were jones ralfy jansen and dandi prabudita')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-14344187-13.html.csv', 'matt brait was below 11')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('2-12206211-4.html.csv', 'the game of june 3 , was against the expos')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-182499-1.html.csv', 'enzyme ala synthase has a location mitochondrion and porphyria of porphyria cutanea tarda')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-1204998-2.html.csv', 'shanghang xian has a population that is below 350000')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-10790397-14.html.csv', 'the team that scored 9.8 (62) is richmond')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-17162128-3.html.csv', 'the united states was the country with the player hale irwin not in the table')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-1717109-6.html.csv', 'in 1987 and 1989 the tournament results where the same 2r')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('2-16013858-11.html.csv', \"when set 4 was 19 - 25 , set 2 was 21 - 25 , and there wasn't a set 5\")\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('1-26593762-3.html.csv', 'george burley was the outgoing manager of the team whose incoming manager was aidy boothroyd')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-24055352-1.html.csv', \"d'andre bell 's height is 6 - 6 the same lance storrs\")\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-13598796-1.html.csv', 'jan johansen is ranked in last place')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-10953197-4.html.csv', 'frank south directed episode 129 titled full metal betsy')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('2-10696381-1.html.csv', 'purdue was the college with an overall pick of smaller than 187 and a round larger than 7 for the defensive end position')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-11780179-1.html.csv', '$5330 is the gdp per capita (nominal) with population less than 5125693')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('2-14344187-13.html.csv', 'canada is in left wing position in round 2')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-261927-1.html.csv', 'salve regina university is the institution with the nickname bison')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-17327458-1.html.csv', 'derek ferguson left a position before january 24')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-182499-1.html.csv', 'the location of substrate porphobilinogen and chromosome 11q23.3 is mitochondrion')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-2509350-3.html.csv', 'the language for sopachuy municipality 6261 is guaran\\xc3\\xad')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-20626467-1.html.csv', 'the time for entrant weighing 54.4 kg was 1 - 38.28 in wawrick farm')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-12531523-5.html.csv', 'ian poulter from the united states had a score of 214')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-12259758-6.html.csv', 'max mirnyi was the partner for the win on june 23 , 2012 against juan sebasti\\xc3\\xa1n cabal dmitry tursunov')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('1-1007688-1.html.csv', 'an undetermined number of cases of relapsing fever happened during 3000 cases of malaria')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-16387653-1.html.csv', 'footscray scored 75 against the visiting richmond team')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('2-1165048-1.html.csv', '8 - 11 was the win / loss of coach peter german')\n",
      "['Contradictory', 'Contradictory', 'Neutral']\n",
      "('2-11963536-7.html.csv', 'on february 22nd , 2008 the rockets were visiting the spurs')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('1-1007688-1.html.csv', 'when typhoid fever had the highest cases with 424 , smallpox had the lowest cases at 8')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-182499-1.html.csv', 'the substrate uroporphyrinogen iii and the product protoporphyrinogen ix , is on chromosome 10q25.2 - q26.3')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-184391-1.html.csv', 'the state of estonia has less than 19000 in the nominal gdp world bank , 2009 (million usd)')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('2-16013858-11.html.csv', 'the information is not na when matching dates jun 25 and when set 3 is 19 - 25')\n",
      "['Contradictory', 'Neutral', 'Entailed']\n",
      "('2-13598796-1.html.csv', 'there are 2 draws with more that 107 points by the artist ellinor franzen')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-14344187-13.html.csv', 'in round 2 sweden is in the right wing position')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-26211058-1.html.csv', 'the specimen weight / size for the estimated exposure (mrem) / hr* is 0.03 is 1')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-11872185-5.html.csv', 'dabangg is the movie with an opening day on wednesday and a rank of 10')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-12536586-1.html.csv', 'the game on october 9 , 1983 had the lowest attendance of the year')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-16785772-6.html.csv', 'the lowest number of points scored when there were 1500 in attendance in boston was 9')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('2-1478772-2.html.csv', 'december 24 , 1977 was the date the st. louis rams played with the baltimore colts at home')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-24055352-1.html.csv', \"kammeon holsey 's height is 6 - 8 the same lance storrs\")\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-1234504-1.html.csv', 'there are only two constructions (610 & 659) that have the wheel arrangement of 2 - 6 - 0')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('2-17358229-1.html.csv', 'munich , germany hosted 12th position european championships')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-28081876-4.html.csv', 'the episode with production code 211 was i see her face everywhere')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-11870943-8.html.csv', 'hte categorization in 2011 was a when it was a in 2008 , a in 2012 and qf in 2010')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-27437601-2.html.csv', 'the series number with the episode called shock waves is 250.0')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-1122578-1.html.csv', 'there are laps for a time / retired of tyre and a grid smaller than 10')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('1-1007688-1.html.csv', 'there were 170 cases of typhoid fever and 4 cases of relapsing fever in 1929')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-261927-1.html.csv', 'massachusetts institute of technology (mit) is the location with the nickname blue & gold')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-11786754-5.html.csv', \"rob turner has the highest avg. at 11.7 and the third most td 's\")\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('2-17301013-5.html.csv', 'the home team on january 30 with 23 points as pittsburgh')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-12207449-6.html.csv', 'the final score of the game played on august 6 is 8 - 3')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-17162128-3.html.csv', 'the total for hale irwin is listed as wd in year (s) won in 1996')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-2849652-2.html.csv', 'the 1st tournament associated with bowling was in 2006')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-17162128-3.html.csv', 'steve jones is the player when the country is united states and the total is less than 154')\n",
      "['Contradictory', 'Contradictory', 'Neutral']\n",
      "('2-11872185-5.html.csv', 'the average rank of dharma productions is four')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-12206211-4.html.csv', 'at the record 32 - 37 the royals lost by 4')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-12531523-5.html.csv', 'phil mickelson has the score 72 + 67 + 69 = 208')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-10953197-4.html.csv', 'no episode has a production code of 2395113a')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-18223552-1.html.csv', '11 , 372 people attended the match on 3 august 1993 with result f - a 0 - 2 and h / a of n')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-1717109-6.html.csv', 'the 1987 result for the canada tournament was rr')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-14319023-2.html.csv', 'when the girls singles is lindaweni fanetri , the mixed doubles is wifqi windarto debby susanto after the year 2007')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('1-27437601-2.html.csv', 'there are more than 241 series for season 12')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-1007688-1.html.csv', 'the number of typhoid fever cases in 1934 was approximately the same in 1929 and 1930')\n",
      "['Contradictory', 'Neutral', 'Neutral']\n",
      "('1-21781578-2.html.csv', 'the season number for production code e2110 was 14')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-16965329-5.html.csv', 'the opponent in the banja luka tournament was carlos berlocq with a score of 4 - 6 , 4 - 6')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-17344918-1.html.csv', '3 - 0 was the 2nd leg when san pedro was the 2nd place winner')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-12512153-4.html.csv', 'pat perez placed lower than health slocum with a score of 67')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('1-10953197-4.html.csv', 'frank south directed all the episodes till full metal betsu')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('2-15532127-1.html.csv', 'on june 1st , 1997 , there were 3 competitions with a result of 5 - 0 and the scores were 1 - 0 , 3 - 0 , and 4 - 0')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('2-12805568-1.html.csv', 'the reactortype vver - 365 (prototype) had a gross capacity of 1000 mw and was shutdown on 29.08.1990')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('2-11780179-1.html.csv', 'uzbekistan is the country that has a gdp (nominal) less than $29.9 billion')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-1007688-1.html.csv', 'in 1935 , when there were 4 cases of smallpox , there were 140 cases of typhus')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('1-29728787-1.html.csv', 'karl ridderbusch was the la roche in a year after 1972')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-20626467-1.html.csv', 'the result for the time of 1 - 26.21 was 1st on 20 / 09 / 08')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-16013858-11.html.csv', 'on june 26 the score in set 4 was 15 - 13')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-10883333-13.html.csv', 'essendon scored 18.18 (132)')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-11872185-5.html.csv', 'in 2010 , excel entertainment was the studio for dabangg , which had an opening day net gross of 14 , 45 , 00000')\n",
      "['Contradictory', 'Contradictory', 'Neutral']\n",
      "('2-17162128-3.html.csv', 'steve jones won in multiple years with a 154 total')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-1341640-14.html.csv', 'cardiss collins was first elected as democrat in 1969')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-21995420-9.html.csv', 'if the school is far eastern university feu cheering squad , then the tumbling number is 49')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-2509350-3.html.csv', 'the language for sopachuy 10 is quechua')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-14319023-2.html.csv', 'in 2009 , when the girls doubles is anneke feinya agustin and wenny setiawati , the mixed doubles is wifqi windarto and debby susanto')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-12805568-1.html.csv', \"the vver - 440 / 179 's gross capacity is 537 mw while the electricity grid for it is 32.58.4568\")\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('2-14347546-5.html.csv', 'the record for the game with under 40 points , over game 25 and with a 2 - 0 score is 15 - 7 - 7 - 1')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-16965329-5.html.csv', 'brasov tournament was not against daniel eisner')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('1-23696862-6.html.csv', 'the greatest amount of wsop bracelets anyone had is zero')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-17327458-1.html.csv', 'derek ferguson was sacked on january 24th')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('2-184391-1.html.csv', 'slovenia was adopted in 1999')\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('2-184391-1.html.csv', 'for adopted 1999 - 01 - 01 , the state of portugal has a relative gdp of total (nominal) 1.83% which is lower than the relative gdp of total (nominal) for ireland with the same adopted date')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('2-17358229-1.html.csv', 'the world race walking cup held after 2001 in ppodebrady , czech republic and m\\xc3\\xa9zidon - canon , france')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-18281308-2.html.csv', 'kenneth allen won his match against mark bear due to tko (cut) at ifc : rumble on the river')\n",
      "['Contradictory', 'Neutral', 'Entailed']\n",
      "('2-1330308-2.html.csv', \"opponent yurij kiselov 's time was greater than 1:30\")\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-14347546-5.html.csv', 'the florida panthers are the opponents in game 31')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-1028356-3.html.csv', '4 - 6 , 6 - 2 , 6 - 3 is the score with partner sherwood stewart')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-12552861-1.html.csv', \"when sue devlin won the women 's singles in 1957 , robert b. williams ethel marshall won the mixed doubles\")\n",
      "['Contradictory', 'Contradictory', 'Entailed']\n",
      "('2-17344918-1.html.csv', '4 - 1 was the 1st leg for 2004')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('1-27821519-1.html.csv', 'mike bliss had 22 top tens')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-1028356-3.html.csv', 'one match at wimbledon resulted in the score : 3 - 6 , 7 - 6 (5) , 6 - 3')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('1-1028356-3.html.csv', 'it was after the year 1990 when one match was played with jim pugh')\n",
      "['Contradictory', 'Contradictory', 'Contradictory']\n",
      "('2-16013858-11.html.csv', 'set 4 is na when the date before jun 27th and set 3 after 17 - 25')\n",
      "['Contradictory', 'Entailed', 'Entailed']\n",
      "('1-2509350-3.html.csv', 'the most padilla municipality for guarani is 2181')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n",
      "('1-10953197-4.html.csv', 'the number of episodes with a production code of 2395118 is number 26.0')\n",
      "['Contradictory', 'Entailed', 'Contradictory']\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from collections import Counter\n",
    "import pprint\n",
    "\n",
    "t = pandas.read_csv(\"/Users/wenhuchen/Downloads/Batch_3598504_batch_results.csv\")\n",
    "t = t[t.AssignmentStatus==\"Approved\"]\n",
    "\n",
    "\n",
    "def transform(string):\n",
    "    if string == \"Problematic\":\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return string\n",
    "\n",
    "kv_pairs = {}\n",
    "num = 5\n",
    "for i, r in t.iterrows():\n",
    "    for j in range(1, num + 1):\n",
    "        csv_name = r['Input.url{}'.format(j)].split('/')[-1]\n",
    "        if (csv_name, r['Input.s{}'.format(j)]) not in kv_pairs:\n",
    "            kv_pairs[(csv_name, r['Input.s{}'.format(j)])] = [r[\"Input.o{}\".format(j)], r[\"Answer.A{}\".format(j)], \"None\"]\n",
    "        else:\n",
    "            kv_pairs[(csv_name, r['Input.s{}'.format(j)])][2] = r[\"Answer.A{}\".format(j)]\n",
    "\n",
    "#new_kv_pairs = {}\n",
    "#for k, v in kv_pairs.iteritems():\n",
    "#    if \"Problematic\" not in v:\n",
    "#        new_kv_pairs[k] = v\n",
    "        #if v[1] == v[2]:\n",
    "        #    new_kv_pairs[k][0] = v[1]\n",
    "            \n",
    "counter = Counter()\n",
    "p_c = [] \n",
    "for k, v in kv_pairs.iteritems():\n",
    "    tmp = set(v)\n",
    "    if len(tmp) == 1:\n",
    "        p_c.append(1)\n",
    "    elif len(tmp) == 2:\n",
    "        p_c.append(1/3.)\n",
    "    else:\n",
    "        p_c.append(0)\n",
    "    \n",
    "    counter.update(v)\n",
    "\n",
    "p_e = []\n",
    "for i, j in counter.items():\n",
    "    p_e.append(j + 0.0)\n",
    "\n",
    "p_e = [_ / sum(p_e) for _ in p_e]\n",
    "p_e = sum(_**2 for _ in p_e)\n",
    "\n",
    "p_c = sum(p_c) / len(p_c)\n",
    "\n",
    "kappa = (p_c - p_e) / (1 - p_e)\n",
    "print \"kappa = {}\".format(kappa)\n",
    "print counter\n",
    "for k, v in new_kv_pairs.iteritems():\n",
    "    if v[0] == 'Contradictory':\n",
    "        print k\n",
    "        print v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_pairs = {}\n",
    "\n",
    "def decide(s1, s2, s3):\n",
    "    s2int = {'Entailed': 1, 'Neutral': 0, 'Contradictory': -1}\n",
    "    avg_score = (s2int[s1] + s2int[s2] + s2int[s3]) // 3.\n",
    "    if avg_score > 0:\n",
    "        return \"Entailed\"\n",
    "    elif avg_score < 0:\n",
    "        return \"Contradictory\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "for k, v in new_kv_pairs.iteritems():\n",
    "    if k[0] not in cleaned_pairs:\n",
    "        cleaned_pairs[k[0]] = [[k[1]], [decide(*v)]]\n",
    "    else:\n",
    "        cleaned_pairs[k[0]][0].append(k[1])\n",
    "        cleaned_pairs[k[0]][1].append(decide(*v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('READY/cleaned.json', 'w') as f:\n",
    "    json.dump(cleaned_pairs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "t = pandas.read_csv('/Users/wenhuchen/Downloads/clean/negative_partial.csv')\n",
    "t = t[t.AssignmentStatus==\"Approved\"]\n",
    "\n",
    "print len(t)\n",
    "finished = []\n",
    "for i, row in t.iterrows():\n",
    "    for j in range(1, 11):\n",
    "        finished.append(row['Input.s{}'.format(j)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "\n",
    "with open('READY/training_all.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open('data/table_to_page.json') as f:\n",
    "    mapping = json.load(f)\n",
    "\n",
    "dummy = [\n",
    "    # refuted\n",
    "    [\n",
    "        'https://raw.githubusercontent.com/wenhuchen/Table-Fact-Checking/master/data/all_csv/2-18847467-2.html.csv',\n",
    "        'chicago bears has won the game in september',\n",
    "        '1982 new orleans saints season',\n",
    "        'https://en.wikipedia.org/wiki/1982_New_Orleans_Saints_season'\n",
    "    ],\n",
    "    # erroneous\n",
    "    [\n",
    "        'https://raw.githubusercontent.com/wenhuchen/Table-Fact-Checking/master/data/all_csv/2-18847467-2.html.csv',\n",
    "        'chicago bears is the best team in the league',\n",
    "        '1982 new orleans saints season',\n",
    "        'https://en.wikipedia.org/wiki/1982_New_Orleans_Saints_season'\n",
    "    ],\n",
    "    [\n",
    "        'https://raw.githubusercontent.com/wenhuchen/Table-Fact-Checking/master/data/all_csv/2-18847467-2.html.csv',\n",
    "        'the ninth week against atlant falcons was a big win with 35 - 6',\n",
    "        '1982 new orleans saints season',\n",
    "        'https://en.wikipedia.org/wiki/1982_New_Orleans_Saints_season'\n",
    "    ],\n",
    "    [\n",
    "        'https://raw.githubusercontent.com/wenhuchen/Table-Fact-Checking/master/data/all_csv/2-18847467-2.html.csv',\n",
    "        'the result against st. lous cardinals was a lost',\n",
    "        '1982 new orleans saints season',\n",
    "        'https://en.wikipedia.org/wiki/1982_New_Orleans_Saints_season'\n",
    "    ],\n",
    "    [\n",
    "        'https://raw.githubusercontent.com/wenhuchen/Table-Fact-Checking/master/data/all_csv/2-18847467-2.html.csv',\n",
    "        'san francisco 49ers was competing on noveber 28 , 1982',\n",
    "        '1982 new orleans saints season',\n",
    "        'https://en.wikipedia.org/wiki/1982_New_Orleans_Saints_season'\n",
    "    ],\n",
    "        [\n",
    "        'https://raw.githubusercontent.com/wenhuchen/Table-Fact-Checking/master/data/all_csv/2-18847467-2.html.csv',\n",
    "        'san francisco is is opponent where week is number',\n",
    "        '1982 new orleans saints season',\n",
    "        'https://en.wikipedia.org/wiki/1982_New_Orleans_Saints_season'\n",
    "    ]\n",
    "]\n",
    "    \n",
    "num = 10\n",
    "count = 0\n",
    "with open('verify_inputs_fake.csv', 'w') as fs:\n",
    "    fields = []\n",
    "    for i in range(0, num + 1):\n",
    "        fields.extend(['wiki{}'.format(i), 'url{}'.format(i), 's{}'.format(i), 'topic{}'.format(i)])\n",
    "    csvwriter = csv.DictWriter(fs, fieldnames=fields)\n",
    "    csvwriter.writeheader()\n",
    "\n",
    "    seed = random.choice(range(0, len(dummy)))\n",
    "    buf = {'wiki0': dummy[seed][3], 'topic0': dummy[seed][2], 'url0': dummy[seed][0], 's0': dummy[seed][1]}\n",
    "    for k, v in data.iteritems():\n",
    "        entry = data[k]\n",
    "        for sent, lab in zip(entry[0], entry[1]):\n",
    "            if lab == 0:\n",
    "                cur = len(buf) // 4\n",
    "                if 'url10' in buf:\n",
    "                    csvwriter.writerow(buf)\n",
    "                    seed = random.choice(range(0, len(dummy)))\n",
    "                    buf = {'wiki0': dummy[seed][3], 'topic0': dummy[seed][2], 'url0': dummy[seed][0], 's0': dummy[seed][1]}\n",
    "                    cur = 1\n",
    "                    count += 1\n",
    "                if sent in finished:\n",
    "                    continue\n",
    "                buf['url{}'.format(cur)] = 'https://raw.githubusercontent.com/wenhuchen/Table-Fact-Checking/master/data/all_csv/' + k\n",
    "                buf['s{}'.format(cur)] = sent\n",
    "                if k in mapping:\n",
    "                    buf['wiki{}'.format(cur)] = mapping[k][1]\n",
    "                    buf['topic{}'.format(cur)] = mapping[k][0]\n",
    "                else:\n",
    "                    buf['wiki{}'.format(cur)] = \"#\"\n",
    "                    buf['topic{}'.format(cur)] = \"None\"\n",
    "        if count % 500 == 0:\n",
    "            print count\n",
    "        #if count > 30:\n",
    "        #    break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "import json\n",
    "import csv\n",
    "\n",
    "with open('READY/training_all.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "num = 11\n",
    "count = 0\n",
    "with open('verify_inputs_fake.csv', 'w') as fs:\n",
    "    fields = []\n",
    "    for i in range(0, num):\n",
    "        fields.extend(['wiki{}'.format(i), 'url{}'.format(i), 's{}'.format(i), 'o{}'.format(i)])\n",
    "    csvwriter = csv.DictWriter(fs, fieldnames=fields)\n",
    "    csvwriter.writeheader()\n",
    "\n",
    "    buf = {}\n",
    "    for k, v in data.iteritems():\n",
    "        entry = data[k]\n",
    "        for sent, lab in zip(entry[0], entry[1]):\n",
    "            cur = len(buf) // 3 + 1\n",
    "            if cur > num:\n",
    "                csvwriter.writerow(buf)\n",
    "                buf = {}\n",
    "                cur = 1\n",
    "                count += 1\n",
    "            buf['url{}'.format(cur)] = 'https://raw.githubusercontent.com/wenhuchen/Table-Fact-Checking/master/data/all_csv/' + k\n",
    "            buf['s{}'.format(cur)] = sent\n",
    "            if lab == 1:\n",
    "                buf['o{}'.format(cur)] = \"Entailed\"\n",
    "            else:\n",
    "                buf['o{}'.format(cur)] = \"Contradictory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "with open('all_sources/full.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line.strip()))\n",
    "    #mapping[str(d['goldAnnotation']['titleId']) + '-' + str(d['tableId'])] = d['goldAnnotation']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "for d in data:\n",
    "    mapping[str(d['pgId']) + '-' + str(d['tableId'])] = d['pgTitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "tiny_mapping = {}\n",
    "for f in os.listdir('data/all_csv/'):\n",
    "    if f.endswith('.csv'):\n",
    "        _, pageid, tableid = f.split('.')[0].split('-')\n",
    "        if pageid + '-' + tableid in mapping:\n",
    "            tiny_mapping[f] = \"https://en.wikipedia.org/wiki/\" + \"_\".join(mapping[pageid + '-' + tableid].split(' '))\n",
    "\n",
    "with open('data/table_to_page.json', 'w') as f:\n",
    "    json.dump(tiny_mapping, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/table_to_page.json', 'r') as f:\n",
    "    tiny_mapping = json.load(f)\n",
    "\n",
    "print len(tiny_mapping)\n",
    "print tiny_mapping['1-18974269-1.html.csv']\n",
    "#print tiny_mapping['1-1007688-1.html.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "import urllib\n",
    "import json\n",
    "\n",
    "with open('data/table_to_page.json', 'r') as f:\n",
    "    tiny_mapping = json.load(f)\n",
    "    \n",
    "new_tiny_mapping = {}\n",
    "for k, v in tiny_mapping.iteritems():\n",
    "    new_tiny_mapping[k] = \"https://en.wikipedia.org/wiki/\" + urllib.quote(v[30:].encode('utf8'))\n",
    "\n",
    "with open('data/table_to_page_new.json', 'w') as f:\n",
    "    json.dump(new_tiny_mapping, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "t = pandas.read_csv('v5_write_input.csv')\n",
    "length = len(t)\n",
    "\n",
    "t = t.head(3000).tail(2000)\n",
    "#t = t.head(1000)\n",
    "\n",
    "t.to_csv('v5_write_input_1000_3000.csv', index=False)\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas\n",
    "\n",
    "t = pandas.read_csv(\"/Users/wenhuchen/Downloads/harvest-v2/first1000.csv\")\n",
    "print len(t)\n",
    "t = t[t.AssignmentStatus==\"Approved\"]\n",
    "print len(t)\n",
    "index = 0\n",
    "num = 5\n",
    "finished = {}\n",
    "for i,r in t.iterrows():\n",
    "    html_name = r['Input.url1']\n",
    "    html_name = html_name.split('/')[-1]\n",
    "    for j in range(1, num + 1):\n",
    "        orig_input = r[\"Answer.d{}\".format(j)]\n",
    "        #if isinstance(orig_input, str) and orig_input.lower() in [\"na\", \"n/a\", \"no\"]:\n",
    "        #    print \"error\"\n",
    "        if isinstance(orig_input, str) and len(orig_input.split(' ')) > 3:\n",
    "            replaced_sent = substitute(orig_input)\n",
    "            #replaced_sent = orig_input\n",
    "            index += 1\n",
    "            if html_name not in finished:\n",
    "                finished[html_name] = [[replaced_sent], [1]]\n",
    "            else:\n",
    "                finished[html_name][0].append(replaced_sent)\n",
    "                finished[html_name][1].append(1)\n",
    "\n",
    "with open(\"READY/round2_first1000.json\",'w') as f:\n",
    "    json.dump(finished, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas\n",
    "\n",
    "t = pandas.read_csv(\"/Users/wenhuchen/Downloads/harvest-v2/last4000.csv\")\n",
    "print len(t)\n",
    "t = t[t.AssignmentStatus==\"Approved\"]\n",
    "print len(t)\n",
    "index = 0\n",
    "num = 5\n",
    "finished = {}\n",
    "for i,r in t.iterrows():\n",
    "    html_name = r['Input.url1']\n",
    "    html_name = html_name.split('/')[-1]\n",
    "    for j in range(1, num + 1):\n",
    "        orig_input = r[\"Answer.d{}\".format(j)]\n",
    "        #if isinstance(orig_input, str) and orig_input.lower() in [\"na\", \"n/a\", \"no\"]:\n",
    "        #    print \"error\"\n",
    "        if isinstance(orig_input, str) and len(orig_input.split(' ')) > 3:\n",
    "            replaced_sent = substitute(orig_input)\n",
    "            #replaced_sent = orig_input\n",
    "            index += 1\n",
    "            if html_name not in finished:\n",
    "                finished[html_name] = [[replaced_sent], [1]]\n",
    "            else:\n",
    "                finished[html_name][0].append(replaced_sent)\n",
    "                finished[html_name][1].append(1)\n",
    "\n",
    "with open(\"READY/round2_last4000.json\",'w') as f:\n",
    "    json.dump(finished, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas\n",
    "\n",
    "t = pandas.read_csv(\"/Users/wenhuchen/Downloads/harvest-v2/middle2000.csv\")\n",
    "print len(t)\n",
    "t = t[t.AssignmentStatus==\"Approved\"]\n",
    "print len(t)\n",
    "index = 0\n",
    "num = 5\n",
    "finished = {}\n",
    "for i,r in t.iterrows():\n",
    "    html_name = r['Input.url1']\n",
    "    html_name = html_name.split('/')[-1]\n",
    "    for j in range(1, num + 1):\n",
    "        orig_input = r[\"Answer.d{}\".format(j)]\n",
    "        #if isinstance(orig_input, str) and orig_input.lower() in [\"na\", \"n/a\", \"no\"]:\n",
    "        #    print \"error\"\n",
    "        if isinstance(orig_input, str) and len(orig_input.split(' ')) > 3:\n",
    "            replaced_sent = substitute(orig_input)\n",
    "            #replaced_sent = orig_input\n",
    "            index += 1\n",
    "            if html_name not in finished:\n",
    "                finished[html_name] = [[replaced_sent], [1]]\n",
    "            else:\n",
    "                finished[html_name][0].append(replaced_sent)\n",
    "                finished[html_name][1].append(1)\n",
    "\n",
    "with open(\"READY/round2_middle2000.json\",'w') as f:\n",
    "    json.dump(finished, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "import csv\n",
    "\n",
    "with open(\"READY/round2_first1000.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open(\"data/table_to_page.json\") as f:\n",
    "    mapping = json.load(f)\n",
    "    \n",
    "fields = ['url1', 'wiki1', 'topic1', 's1', 's2', 's3', 's4', 's5']\n",
    "index = 0\n",
    "with open(\"rewrite_fake_first1000.csv\", 'w') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "    for k, v in data.iteritems():\n",
    "        for i in range(0, len(v[0]), 5):\n",
    "            v_s = v[0][i:i+5]\n",
    "            field = {}\n",
    "            for j, s in enumerate(v_s):\n",
    "                field['s{}'.format(j + 1)] = s\n",
    "            field['url1'] = 'https://raw.githubusercontent.com/wenhuchen/Table-Fact-Checking/master/data/all_csv/' + k\n",
    "            field['wiki1'] = mapping[k][1]\n",
    "            field['topic1'] = mapping[k][0]\n",
    "            writer.writerow(field)\n",
    "            index += 1\n",
    "        #if index > 20:\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "import csv\n",
    "\n",
    "with open(\"READY/round2_middle2000.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open(\"data/table_to_page.json\") as f:\n",
    "    mapping = json.load(f)\n",
    "    \n",
    "fields = ['url1', 'wiki1', 'topic1', 's1', 's2', 's3', 's4', 's5']\n",
    "index = 0\n",
    "with open(\"rewrite_fake_middle2000.csv\", 'w') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "    for k, v in data.iteritems():\n",
    "        for i in range(0, len(v[0]), 5):\n",
    "            v_s = v[0][i:i+5]\n",
    "            field = {}\n",
    "            for j, s in enumerate(v_s):\n",
    "                field['s{}'.format(j + 1)] = s\n",
    "            field['url1'] = 'https://raw.githubusercontent.com/wenhuchen/Table-Fact-Checking/master/data/all_csv/' + k\n",
    "            field['wiki1'] = mapping[k][1]\n",
    "            field['topic1'] = mapping[k][0]\n",
    "            writer.writerow(field)\n",
    "            index += 1\n",
    "        #if index > 20:\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "import csv\n",
    "\n",
    "with open(\"READY/round2_last4000.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "files = data.keys()\n",
    "num = 1473\n",
    "shiyang_data = files[:num]\n",
    "wanghong_data = files[num:2*num]\n",
    "yunkai_data = files[2*num:]\n",
    "    \n",
    "with open(\"data/table_to_page.json\") as f:\n",
    "    mapping = json.load(f)\n",
    "    \n",
    "fields = ['url1', 'wiki1', 'topic1', 's1', 's2', 's3', 's4', 's5']\n",
    "\n",
    "with open(\"rewrite_fake_shiyang.csv\", 'w') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "    for k in shiyang_data:\n",
    "        v = data[k]\n",
    "        for i in range(0, len(v[0]), 5):\n",
    "            v_s = v[0][i:i+5]\n",
    "            field = {}\n",
    "            for j, s in enumerate(v_s):\n",
    "                field['s{}'.format(j + 1)] = s\n",
    "            field['url1'] = 'https://raw.githubusercontent.com/wenhuchen/Table-Fact-Checking/master/data/all_csv/' + k\n",
    "            field['wiki1'] = mapping[k][1]\n",
    "            field['topic1'] = mapping[k][0]\n",
    "            writer.writerow(field)\n",
    "            \n",
    "with open(\"rewrite_fake_yunkai.csv\", 'w') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "    for k in yunkai_data:\n",
    "        v = data[k]\n",
    "        for i in range(0, len(v[0]), 5):\n",
    "            v_s = v[0][i:i+5]\n",
    "            field = {}\n",
    "            for j, s in enumerate(v_s):\n",
    "                field['s{}'.format(j + 1)] = s\n",
    "            field['url1'] = 'https://raw.githubusercontent.com/wenhuchen/Table-Fact-Checking/master/data/all_csv/' + k\n",
    "            field['wiki1'] = mapping[k][1]\n",
    "            field['topic1'] = mapping[k][0]\n",
    "            writer.writerow(field)\n",
    "            \n",
    "with open(\"rewrite_fake_wanghong.csv\", 'w') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "    for k in wanghong_data:\n",
    "        v = data[k]\n",
    "        for i in range(0, len(v[0]), 5):\n",
    "            v_s = v[0][i:i+5]\n",
    "            field = {}\n",
    "            for j, s in enumerate(v_s):\n",
    "                field['s{}'.format(j + 1)] = s\n",
    "            field['url1'] = 'https://raw.githubusercontent.com/wenhuchen/Table-Fact-Checking/master/data/all_csv/' + k\n",
    "            field['wiki1'] = mapping[k][1]\n",
    "            field['topic1'] = mapping[k][0]\n",
    "            writer.writerow(field)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "t = pandas.read_csv('/Users/wenhuchen/Downloads/harvest-v3/partial_positive.csv')\n",
    "t = t[t.AssignmentStatus==\"Approved\"]\n",
    "\n",
    "mapping = {}\n",
    "for i, r in t.iterrows():\n",
    "    for i in range(1, 6):\n",
    "        name = r['Input.url{}'.format(i)].split('/')[-1]\n",
    "        if name not in mapping:\n",
    "            mapping[name] = [[r['Input.s{}'.format(i)]], [r['Answer.A{}'.format(i)]]]\n",
    "        else:\n",
    "            mapping[name][0].append(r['Input.s{}'.format(i)])\n",
    "            mapping[name][1].append(r['Answer.A{}'.format(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('READY/verify.json', 'w') as f:\n",
    "    json.dump(mapping, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def postprocess(inp, backbone):\n",
    "    print inp\n",
    "    new_str = []\n",
    "    for w in inp.split(' '):\n",
    "        if w[0] in list(string.lowercase) and w in backbone:\n",
    "            new_str.append(w.capitalize())\n",
    "        else:\n",
    "            new_str.append(w)\n",
    "    inp = \" \".join(new_str)\n",
    "    \n",
    "    inp = re.sub(r'([^0-9])\\.', r'\\1', inp)\n",
    "    inp = re.sub(r'ʼ', '', inp)\n",
    "    inp = re.sub(r'ʻ', '', inp)\n",
    "    #inp = re.sub(r' ?- ?', '-', inp)\n",
    "    #inp = re.sub(r' ?\\+ ?', '+', inp)\n",
    "    #inp = re.sub(r' ?/ ?', '/', inp)\n",
    "    #inp = re.sub(r\" ?'s\", \"'s\", inp)\n",
    "    #inp = re.sub(r\" ?'nt\", \"'nt\", inp)\n",
    "    inp = inp + '.'\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fa + faf - fafa / faf he does'nt is n't fa. faf\n",
      "fa\n",
      "+\n",
      "faf\n",
      "-\n",
      "fafa\n",
      "/\n",
      "faf\n",
      "he\n",
      "does'nt\n",
      "is\n",
      "n't\n",
      "fa.\n",
      "faf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"fa+faf-fafa/faf he does'nt is n't fa faf.\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocess(\"fa + faf - fafa / faf he does'nt is n't fa. faf\", ['kkk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31350\n",
      "american spirit team had the best and qual 2 time of 59.073\n",
      "michel jourdain , jr. 's best and qual 2 time was 58.700\n",
      "jimmy vasser with the team american spirit team johansson had qual 1 of 59.382 and a qual 2 of 58.861\n",
      "the qual 1 was 1:00.003 and qual 2 was for 59.822 tiago monteiro\n",
      "paul tracy with team team player 's had a qual 1 time of 59.804 and a best of time of 58.405\n",
      "the game that scored 7 - 3 had a record of 38 - 18\n",
      "the game with 13 lsu as the opponent had a score of 8 - 2\n",
      "the game that ole mississippi was the opponent to mckean (4 - 1) who loss was played at the regions field\n",
      "the opponent 23 south carolina has a record of 39 - 19\n",
      "the may 24 game had a record of 40 - 20\n",
      "episode with production code 7aff03 was directed by brad turner\n",
      "in season 19 , episode day 7: 2:00 a.m. - 3:00 a.m. there were 10.34 million viewers\n",
      "37 - 27 (14 - 10) was the recorded conference of the wac conference\n",
      "missouri valley is the conference of the wichita state school\n",
      "the smoke point for 30 g of monosaturated fat is °c\n",
      "100 g of total fat has 20 g (84 g in high oleic variety) of monounsaturated fat and 69 g (4 g in high oleic variety) of polyunsaturated fat\n",
      "28 g of polyunsaturated fat has a total fat of 100 g and a saturated fat of 7 g\n",
      "total fat of 100 g has a polyunsaturated fat of 37 g combined with 25 g of saturated fat\n",
      "the total attendance for week 8 is 48667\n",
      "the only team that drafted players from the university of maryland was chivas usa\n",
      "the houston dynamo team drafted samuel appiah\n",
      "the attendance in week 2 was 20114\n",
      "the record after the game on july 28 was 2 - 1\n",
      "alex yoong started in grid position 22\n",
      "driver jacques villeneuve for bar - honda constructor was on grid 9\n",
      "a school in the state 's authority had a role of 651\n",
      "the decile for the roll of 651 is 3\n",
      "1 - 8 were the the years for redhill school which is an authority of the state\n",
      "the sum roll for a school of karaka area was 91\n",
      "carey scurry , no. 22 , played during 1985 - 88\n",
      "john starks plays in the position shooting guard\n",
      "deshawn stevenson plays in the position shooting guard\n",
      "kirk snyder played during 2004 - 05\n",
      "john starks played from 2000 to 2002\n",
      "kirk snyder played for nevada\n",
      "ersc ottobrunn played 10 , lost 4 , and had 11 points\n",
      "tom loughridge is suzuki 's lowest ranked rider\n",
      "tom loughridge is ranked 7th and is a rider for team suzuki\n",
      "ronnie peterson was the winning driver at the monza circuit\n",
      "jody scheckter had the fastest lap on 7 july at the french grand prix\n",
      "the race at the interlagos circuit was held on 27 january\n",
      "the station code kuda departs at 17:08 and travels 2314 kilometers\n",
      "the station with code tcr has an arrival time of 02:20\n",
      "ersc ottobrunn played 10 , lost 4 , and had 11 points\n",
      "tom loughridge is suzuki 's lowest ranked rider\n",
      "tom loughridge is ranked 7th and is a rider for team suzuki\n",
      "ronnie peterson was the winning driver at the monza circuit\n",
      "jody scheckter had the fastest lap on 7 july at the french grand prix\n",
      "the race at the interlagos circuit was held on 27 january\n",
      "it is listed for a departure at 9:35 that will be 1676 kilometers\n",
      "the station code kuda departs at 17:08 and travels 2314 kilometers\n",
      "the station with code tcr has an arrival time of 02:20\n",
      "malta played one game and scored 36 points\n",
      "on may 28 , dave stockton won with a purse of $1100000\n",
      "mike hill won the kroger senior classic\n",
      "the ford senior players championship was held on july 16\n",
      "the quicksilver classic was held in pennsylvania\n",
      "hale irwin (2) scored 199 ( - 17) on oct 1\n",
      "on may 28 , dave stockton (11) won a purse ( $ ) value of 1100000\n",
      "carey scurry , no. 22 , played from 1985 to 1988\n",
      "john starks position was shooting guard\n",
      "kirk snyder played guard from the years 2004 to 2005\n",
      "kirk snyder played in school for nevada\n",
      "overall , 14 goals were scored at moses mabhida stadium\n",
      "at royal bafokeng stadium , the average goals scored per match was 1.25\n",
      "the home game of essendon had a small crowd of 12865\n",
      "on august 28 , 1971 hawthorn scored 18.16 at the glenferrie oval\n",
      "in atlanta with a score of w.109 - 101 (ot) rafter alston had 8 high assists\n",
      "w 109 - 101 (ot) was the score on april 8\n",
      "plains was class a for the 1988 - 89 and 1989 - 90 school years\n",
      "lindsay was class a and elkhart was class aa during the 2010 - 11 school year\n",
      "the 1995 - 96 school year class a went to rule and the class aa went to stamford\n",
      "driver pedro de la rosa had 29 laps\n",
      "the time / retired for the driver on grid 18 was brakes\n",
      "svetlana zelenkovskaya was nominated for the best debut award for the film anastasiya slutskaya\n",
      "the film , falling up , was nominated for the best actress in a supporting role category\n",
      "danuta stenka is the name of the actress nominated for the best actress in a leading role category for the film , chopin : desire for love\n",
      "chopin : desire for love had a nomination for best actress in a leading role by danuta stenka\n",
      "for the film name shum vetra , the actors name is alla sergiyko\n",
      "the nomination for the best actor in a supporting role was for the film name 27 stolen kisses\n",
      "svetlana zelenkovskaya was nominated for the best debut award for the film anastasiya slutskaya\n",
      "the film falling up received a nomination for best actress in a supporting role\n",
      "at ellis park stadium , where 19 overall goals were scored , the attendance was 372843\n",
      "the elevation of the city port elizabeth is 0 (sea level)\n",
      "the average attendance per match at the royal bafokeng stadium is 32283 , with an elevation of 1500 m\n",
      "the average attendance at the royal bafokeng stadium at elevation 1500 m is approximately 32283 fans\n",
      "the labour party received 11484 votes\n",
      "the independent party received 551 votes\n",
      "the labor party votes totalled to 11484\n",
      "the uk independence party and the independent party had less than 11484 votes\n",
      "the attendance on december 16th at washington redskins was 49484\n",
      "giovanni visconti is the general classification for stage 13\n",
      "the player with the nationality of tri is moving to free agent\n",
      "the iata for the city of jeddah in saudi arabia is jed\n",
      "the iata for the city of jessore in bangladesh is jsr\n",
      "the suvarnabhumi airport is located in bangkok , thailand\n",
      "the iata for the city of kuala lumpur is kul , located in malaysia\n",
      "the iata for jeddah is jed\n",
      "the iata for jessore is jsr\n",
      "the city for thailand is bangkok\n",
      "the iata for kuala lumpur is kul\n",
      "at diedenbergen in 1999 , polonia bydgoszcz won , msc diedenbergen was the runner up , and mega - lada togliatti finished third\n",
      "the winner of the tournament , kroger senior classic , is named mike hill (17)\n",
      "ford senior player championship was on jul 16\n",
      "the tournament quicksilver classic is in pennsylvania\n",
      "muirfield was located in gullane , scotland\n",
      "south melbourne was the away team in the match at corio oval\n",
      "michael barrett , an infielder from atlanta , georgia , was drafted by the expos\n",
      "the pirates drafted chad hermansen from green valley high school in the 1st round of the 1995 season\n",
      "green valley high school had a player drafted into the mlb for an infielder position\n",
      "danuta stenka was nominated for best actress in a leading role for her role in the film chopin : desire for love\n",
      "danuta stenka was nominated for best actress in a leading role for her role in the film chopin : desire for love\n",
      "the actor named alla sergiyko starred in the film named shum vetra\n",
      "the film was 27 stolen kisses that had a nomination for best actor in a supporting role\n",
      "home but not alone is episode number 57 in the series\n",
      "haunted hero was aired in season 3 series number 47\n",
      "breen frazier wrote unhappy medium\n",
      "the episode no safe place had 8.95 million us viewers\n",
      "away team footscray had a score of 11.11 (77)\n",
      "home team essendon played against away team geelong on june 20 , 1931\n",
      "plains was named class a for the 2004 - 05 school year\n",
      "the name of the pictorial in the 11 - 98 issue is girls of the acc\n",
      "there was one centerfold in the 9 - 98 issue\n",
      "matt drudge was interviewed in the 8 - 98 issue\n",
      "john peterman was asked 20 questions in the issue where the centerfold is marliece andrada\n",
      "jaime pressly and erika eleniak were featured in the pictorials in the issue where john peterman was asked 20 questions\n",
      "the southland conference had one round of 32\n",
      "the lowest number of bids is 2 for a winning percent of .667\n",
      "the new york islanders were the opponent in game 63\n",
      "daniele bennati had the points classification and giovanni visconti had the general classification during stage 6 , 7 , 9 , 10 , 11 , 12 and 13\n",
      "franco pellizotti is the general classification for stage 3 when daniele bennati had the points classification and morris possoni had the young rider classification\n",
      "gabriele bosisio and alberto contador were the general classification when riccardo ricco was the young rider classification\n",
      "points classification had no award when chris anker sorensen was the young rider and christian vande veide was the general classification\n",
      "daniele bennati is the point classification of stage 15\n",
      "hawthorn scored 22.12 (144) against north melbourne at the glenferrie oval\n",
      "in 2000 , the population of ok is 68190 which is a a078 + 17.22% change from 1990 - 2000\n",
      "the rank of a result of (msa 348) has a population of 99962 in 2000\n",
      "the 2000 population in ok with a 1990 - 2000 percent change of a078 + 17.22% is 68190\n",
      "collingwood home team 's score when they played against north melbourne was 22.22\n",
      "carlton home team 's score when they played melbourne away team was 18.14\n",
      "there was a crowd of 8000 people at hawthorn 's home match\n",
      "footscray played against st kilda with a winning score of 11.11 (77)\n",
      "essendon played at home against geelong on 20 june 1931\n",
      "when collingwood played north melbourne at home , their score was 22.22 (154)\n",
      "carlton was the home team against melbourne with a winning score of 18.14 (122)\n",
      "hawthorn was the home team and fitzroy was the away team when the crowd was 8000\n",
      "the player matt nagy had less than 197 yards and a long of 6\n",
      "petal high school had an infielder drafted to the marlins\n",
      "the record after the game on april 15 was 5 - 4\n",
      "reds is the opponent that leads to 10 - 13 record\n",
      "the record after the april 6 game was 2 - 0\n",
      "the score on april 12 game was 2 - 4\n",
      "wells (0 - 1) lost the game on april 6\n",
      "in 2009 british formula three had 109 points , but no fastest laps\n",
      "in 2008 , carlin motorsport had no wins\n",
      "he had 20 races in each of the years 2007 , 2008 , with formula renault uk and in 2009 with british formula three\n",
      "there is a peak named fountains fell south top in the class nuttall\n",
      "mega - lada was the runner - up in 2004\n",
      "apator toruń finished in 3rd place at pardubice\n",
      "9 xavier had 8 high assists on february 5th\n",
      "there were no wins in the 250cc class in 1971\n",
      "1971 was the earliest year that the yamaha team ranked 21 with less than 45 points\n",
      "the players from the united states that finished t10 are hall sutton , justin leonard , bob estes , mark brooks , paul azinger and tommy aaron\n",
      "the golfer from the country of fiji had a score of 72\n",
      "a prop player with over 45 caps plays for l'aquila\n",
      "the 1990 - 2000 percent change of a result that is estimated to be 45393 in 2007 is a304 + 6.75%\n",
      "the rank of (msa 348) is the result with a population of 99962 in 2000\n",
      "bombardier dash 8 and q400 has 37 - 78 seats available\n",
      "hawthorn scored 150 total goals during the 1971 season\n",
      "matt stevens , who plays prop and has 11 caps , was born on october 1 , 1982\n",
      "george chuter plays for the leicester tigers , and has 12 caps\n",
      "toby flood plays for newcastle in the fly - half position , and has only 9 caps\n",
      "the tour apps is 13 when the career caps show 15\n",
      "the number of career caps for a full back is 0 when tour apps is smaller than 29\n",
      "a.w. ross played fullback for sydney university and totaled 20 career caps\n",
      "the record was 29 - 31 - 4 after a score of 1 - 4\n",
      "the record is 28 - 29 - 4 with less than 62 points , february greater than 16 , and a score of 8 - 7\n",
      "billy andrade is the golfer who scored 68 + 70 + 68 + 66 = 272\n",
      "the golfer with a score of 67 + 67 + 66 + 68 = 268 ranked in 3rd place\n",
      "on december 26th , the score was st louis 3 , pittsburgh 2 , with 20 points accumulated\n",
      "eighteen points were accumulated on december 21 when pittsburgh hosted minnesota in front of a crowd of 5307\n",
      "the points are 18 when the home team is boston\n",
      "hiroshi aoyama was the winner of the spanish grand prix\n",
      "the indianapolis circuit happened on the 30th of august\n",
      "mario simoncelli won the 250cc in round 9\n",
      "shane bond had an over no. of 1 , on 9 - 12 - 2007\n",
      "chris gayle caught kapali on 9 - 13 - 2007 , in johannesburg\n",
      "the townsville crocodiles scored 82 points and the south dragons scored 77 points\n",
      "the townsville crocodiles and south dragons played at the townsville entertainment centre\n",
      "the away team with the lowest crowd number of 2998 is the new zealand breakers\n",
      "the townsville crocodiles played the home team , the south dragons , at hisense arena\n",
      "game 13 was against houston on june 26\n",
      "game 11 was played on june 22\n",
      "utah was the opponent in game 8\n",
      "harvey 's land area is 276.84 km 2\n",
      "the cpu core i5 - 661 has a core clock ( mhz ) of 900 and a memory bandwidth ( gb / s ) of 21.3\n",
      "each cpu has 12 execution units\n",
      "the core i5 - 661 cpu has a 4.0 shader model\n",
      "wales : border to border is directed by ross young\n",
      "episode 2 is devon and cornwall\n",
      "the norway (nor) norway ii team had a time of 1:20.77 for the third run\n",
      "the least number of times an episode was shown from between 1997 and 1998 was one\n",
      "the episode called coop de grace appears one time\n",
      "a scorer of oh seok - jae has a rank of 4 with goals higher than 4\n",
      "four is the lowest one that has matches of 16 and a scorer of park sang - in\n",
      "club yukong elephants has rank of one\n",
      "club of hallelujah fc had four goals and a rank of seven\n",
      "wayne tree rollins , who went to clemson , spent 1993 to 1995 in orlando\n",
      "the total prom in metres for the peak great knoutberry hill is 254\n",
      "627 is the height of gragareth , which is under the hewitt class with a prom less than 86\n",
      "ncaa division i is the classification for the school in the nec conference located in new britain , connecticut\n",
      "central connecticut state university is the institution that is a ncaa division i school and part of the nec conference with a nickname the blue devils\n",
      "franklin pierce university in ncaa division ii is located in rindge , new hampshire\n",
      "post university 's nickname is the eagles\n",
      "america east is the current conference of the river hawks\n",
      "the institution with the nickname penmen is located in manchester , new hampshire\n",
      "when chven - i is a nominative then the ergative is chven - ma\n",
      "michael lembeck directed series number 39 , flying solo\n",
      "for dinamo - bucuresti , the tries against is 32 , and the points against is 213\n",
      "for narbonne , the tries for is 21 , and the tries against is 6\n",
      "for narbonne , the try diff is + 15 , and the points diff is + 71\n",
      "for narbonne , the tries against is 6 , and the try diff is + 15\n",
      "tries against is 32 when points against is 213\n",
      "the team had 21 tries for when they had 6 tries against\n",
      "the nominative mis - i has mis as the dative\n",
      "the ergative is chem - ma when the dative was chem - s\n",
      "when chven - s is the adverbial , the instrumental is chven - s\n",
      "the nominative mis - i has mis - ma as the ergative\n",
      "week 1 event happened on september 3 , 1995\n",
      "the opponent of week 8.0 is at seattle seahawks\n",
      "the result for october 15 1995 is l 23 - 9\n",
      "in week 6 , october 9 1995 , the kansas city chiefs were the opponent and it resulted in a loss of 29 - 23 , with 79288 people attending the game\n",
      "september 3 , 1995 is the date for week 1\n",
      "during game 7 on june 10th , the high assists are listed as mcwilliams (6)\n",
      "rory gallagher from fermanagh had a total of 22 points and an average of 7.14\n",
      "in 5 matches , oison mcconville had a total of 25 points\n",
      "john masius wrote the episode directed by arvin brown\n",
      "series 7 , night moves was viewed by 3.61 million people\n",
      "yielding was written by sarah thorp\n",
      "joou no kyoushitsu was the romaji title that has a japanese title of 女王の教室\n",
      "the romaji title slow dance has eleven episodes\n",
      "the name of the spinning coaster that opened in 2000 in brighton pier is crazy mouse\n",
      "when the try diff was + 15 , there were 6 tries against\n",
      "beverley knight was the singer when the ratings were 1.45 m\n",
      "bruce forsyth had a rating under 1.41 m\n",
      "frank skinner is joe wilkinson 's guest during the august 26 , 2011 broadcast with ratings of 1.64 m\n",
      "the locomotive bl27 (serial no. 83 - 1011) has pacific national blue & yellow livery\n",
      "locomotive bl31 (serial no. 83 - 1015) has a standard gauge\n",
      "the date that the locomotive with a broad gauge and serial number 83 - 1018 is june 1984\n",
      "molpadia linea , a name of amazonian origin , is located at 48.0s latitude and 355.e longitude\n",
      "jeremy richardson wears number 32 , and attended delta state\n",
      "wayne 'tree' rollins , of the clemson school , is from the united states\n",
      "bartonella henselae is the genus / species with the accession number of bx897699.1\n",
      "yp_568432.1 has a sequence similarity of 54\n",
      "hypothetical protein is the gene name for methylobacterium nodulans\n",
      "the gene name for accession number bx897700.1 is hypothetical protein\n",
      "asencio (2 - 4) took the loss on july 30 and the record for the team went to 45 - 59\n",
      "the eigth - place team finished with a time of 5:18.85\n",
      "the 10th - place team finished with a time of 5:19.62\n",
      "the 9th - place american team who finished with a time of 5:19.68 , completed the third run in 1:19.49\n",
      "the norwegian team who finished 13th , with a final time of 5:24.47 , completed the second run in 1:21.18\n",
      "the second - place team from the usa finished run one in 1:17.44\n",
      "james wright was the runner - up at wolverhamptonin in 2004\n",
      "wolverhampton was the venue when jack hargreaves finished third , behind william lawson and lewis bridger in 2005\n",
      "wolverhampton was the venue when ben barker finished third\n",
      "seattle seahawks were the opponent in week 8\n",
      "l 23 - 9 were the results on october 15th , 1995\n",
      "in week 6 , the attendance was 79288 and the result was a loss , 29 - 23\n",
      "player o.j. mayo who 's hometown is huntington , wv , has a height of 6'5\n",
      "derrick rose from simeon career acadamy is from hometown chicago , il\n",
      "the player from south medford high school headed to duke college\n",
      "the player who is headed to duke college is from south medford high school\n",
      "the hometown of the player who is headed to duke college is medford , or\n",
      "when the home team was in north melbourne , the crowd was 10000\n",
      "kyle newman placed third in 2009\n",
      "gary bussel plays defensive back for the denver broncos\n",
      "the kansas city chiefs have a pick of 69\n",
      "the player george kinney from the college of wiley has picked 66\n",
      "self versus self - immersion is a song by the band pendulum , released in 2010\n",
      "r 3 of d 43 has a d 45 of r 5\n",
      "d 41 has r 20 and d 43 has r 18\n",
      "d 46 of majority→ has a d 43 of majority→\n",
      "r 22 of d 42 has a d 46 of r 26\n",
      "the team record was 9 - 2 when they played on november 18 at the izod center\n",
      "morrigan linea was named for a celtic war goddess\n",
      "lampedo linea , located at 293.0e longitude , is 800 km in diameter\n",
      "sara ramirez was nominated for outstanding actress - television series prior to 2008\n",
      "on may 11 , the cleveland indians played\n",
      "the cleveland indians score 11 - 3 = 8 on may 11th\n",
      "the game against the toronto blue jays ended with a score of 2 - 1\n",
      "there is not a school that has a bask score along with an indoor track score of 0 , and a swimming score of 5\n",
      "denmark won the 2007 football game by 3 goals to 1\n",
      "in 1992 france b lose to england b\n",
      "in 1998 , england b was the winner when the loser was russia - 2\n",
      "in 1998 russia - 2 lost playing football against england b\n",
      "the away team 's score was 15.15 (105) with fitzroy as the home team\n",
      "south melbourne 's home side score is 12.13 (85)\n",
      "in 2005 when the mlb team was the toronto blue jays , the fscl team was the orlando shockers\n",
      "alan farina of the orlando shockers played during 2005 and was drafted in the year 2007\n",
      "when winter pines was the fcsl team , the colorado rockies was the mlb team\n",
      "the score when the record went to 33 - 47 was 2 - 1 and the opponent the red sox\n",
      "when the record became 34 - 51 , the game attendance was 55005 and opponent the yankees\n",
      "the red sox were the opponent with the attendance of 31777 on july 3\n",
      "footscray was the away team for the game located at the arden street oval venue\n",
      "the game with the smallest crowd size was when the away team scored 14.21 (105)\n",
      "footscray was the visiting team for the game at the arden street oval\n",
      "6000 spectators saw the 17.16 (118) match at arden street oval\n",
      "otto passman in the only incumbent in district louisiana 5\n",
      "john rarick of district louisiana 6 lost his renomination to a republican gain\n",
      "john breaux is the incumbent of lousiana 's 7th district\n",
      "the crowd total at mcg is 23000\n",
      "when fitzroy was the home team , the away teams score was 4.16 (40)\n",
      "on july 21 , 1951 , the home team score was 5.8 (38)\n",
      "the largest crowd recorded at the arden street oval venue was 14000\n",
      "the average crowd size at the matches where the home team scored 6.12 (48) was 14000\n",
      "the home team was melbourne and had a score of 8.6 (54) , and took place at mcg\n",
      "agneepath from 2012 ranks 7 with an opening week net gross of 81 , 77 , 00000\n",
      "bodyguard from reliance entertainment ranks 4 with an opening week net gross of 100 , 15 , 00000\n",
      "green bay has a swimming score of 9 , a volleyball score of 1 , and a total score of more than 35\n",
      "the score was 0 - 2 met when vladimir malenkikh made a goal at 18:27\n",
      "at 18:27 , met scored and the score was 0 - 2 for met\n",
      "chris drury scored his first goal of the game in a power play at 39:37\n",
      "patty sheehan was the runner up in the corning classic on may 30th , 1982\n",
      "judy rankin was the runner up on august 3 , 1969\n",
      "on may 30 , 1982 , the winning score was - 8 (69 + 72 + 70 + 69 = 280)\n",
      "on september 12 , 1982 carole charbonnier was a runner up with a 1 stroke margin of victory\n",
      "in 1946 , otto passman (d) was re - elected in an unopposed race\n",
      "in 1972 , john breaux (d) was re - elected in louisiana 's 7th district\n",
      "john breaux is the incumbent of louisiana 7\n",
      "otto passman (d) unopposed was re - elected in 1946\n",
      "when john breaux was the incumbent , he was re - elected\n",
      "peggy gardner ranked 5th in 1981 - 82 and marci drexler was also ranked 5th in 1984 - 85\n",
      "rank 8 includes linda prefontaine for 1980 - 81 and liz alvarado in 1984 - 85\n",
      "rank 8 includes linda prefontaine for 1980 - 81 and caryn mckinney in 1983 - 84\n",
      "linda prefontaine was ranked 8th in 1980 - 81 , while liz alvarado was ranked 8th in 1984 - 85\n",
      "episode 3 of the season was directed by jamie babbit\n",
      "episode 34 of the series was titled , magic jordan\n",
      "the original air date of april 9th , 2003 had a production code of 08 - 02 - 214\n",
      "bernie mac dance party was number 28 in the series\n",
      "opponent ilija bozoljac played on a clay surface\n",
      "opponent daniel elsner played at the brasov tournament\n",
      "during the guayaquil tournament on november 5 , 2007 , the score was 3 - 6 , 7 - 6 (6) , 5 - 7\n",
      "opponent ilija bozoljac played at the banja luka tournament and had a score of 4 - 6 , 4 - 6\n",
      "Žydrūnas ilgauskas and anderson varejão scored high rebounds , with 7 , while delonte west had high assists with 10\n",
      "in 1972 , the regular season and playoff attendance in the ivor wynne stadium was 255627\n",
      "the smallest crowd that attended a game was when the away team scored 19.11 (125) points\n",
      "on april 7th , 1979 , 24133 people attended the game at mcg\n",
      "the frequency for ktdl out of trinidad , colorado is 90.7\n",
      "december 15 , 2009 was the airdate for 7 1 - 07\n",
      "the hallmark pilot episode had 157000 viewers\n",
      "the episode mooning and crooning ranked 3 (hallmark) 2 (hallmark + 1)\n",
      "the buckeye savings invitational was the tournament with a winning score of + 3 (71 + 72 + 70 = 213)\n",
      "benito cheng 's pick number is 5\n",
      "richard bachmann 's pba team is the alaska milkmen\n",
      "johnny abarrientos from the college far eastern has a pick number of 3\n",
      "brent spiner was nominated for outstanding actor in a musical\n",
      "there is 1 pick that has an overall of 114\n",
      "daimon shelton , a fullback , has an overall of 184 and a pick of 21\n",
      "cornell college has a low pick of 18\n",
      "26427 people attended the game on may 17th\n",
      "gerald green played the position of guar / forward for the rockets in 2008\n",
      "devin gray of clemson is 6 - 6\n",
      "in 2008 , gerald green played guard / forward for the rockets\n",
      "devin gray went to college at clemson and is 6 - 6\n",
      "the pilot episode ranked 2 (hallmark) 1 (hallmark + 1)\n",
      "the game against julia moriarty of ireland was played on clay\n",
      "sandra kristjánsdóttir plays for iceland\n",
      "the player won the 2011 europe / africa group iiib against ons jabeur of tunisia\n",
      "the player lost the 2009 europe / africa group iiib against anna movsisyan of armenia\n",
      "the college / junior / club team (league) swift current broncos (wchl) has a nationality of canada\n",
      "in round 4 , the college / junior / club team (league) hamilton red wings (oha) has a position of rw\n",
      "round 13 has a position of lw and a college / junior / club team (league) of swift current broncos (wchl)\n",
      "round 10 's nationality is france\n",
      "marlen angelidou was the artist in first place\n",
      "medium tankers can be made for singles or crews\n",
      "depending on the drive wheels , super tankers can be either category 5 or 6\n",
      "the capacity for a mdium tanker with cab size for a single person is 1600 - 3000 liters\n",
      "the cfl team with player ryan folk is the winnipeg blue bombers\n",
      "craig zimmer attended regina college\n",
      "with the 41 pick of the draft , the saskatchewan roughriders selected regina alumni craig zimmer\n",
      "craig zimmer plays lb and was selected by the saskatchewan roughriders\n",
      "anthony mason of cfl team hamilton tiger - cats has a position of ol\n",
      "pick number 43 has a position of lb\n",
      "linda prefontaine was entered in 1980 - 81 , while caryn mckinney was entered in 1984 - 85\n",
      "the only defensive tackle is corey peters , with a pick number of 19\n",
      "the home team essendon scored 15.5 (95) in the venue of windy hill\n",
      "the home team scored 9.10 (64) at vfl park\n",
      "a game was held at vfl park on july 5 , 1975\n",
      "when north melbourne played as the away team , the crowd size was averaged at 10034\n",
      "tayshaun prince , a forward from kentucky , is from the united states\n",
      "the player from duke had nationality from united states\n",
      "during 1999 - 2001 , the point guard from oklahoma had nationality from united states\n",
      "sporting cp had a 1. round in the 1970 - 71 season\n",
      "on february 15 , 1986 , hein vergeer had a distance of 5000 m\n",
      "tommy aaron scored a 71\n",
      "doug basham 's team is the basham brothers\n",
      "greg valentine was eliminated by necro butcher\n",
      "one player 's hometown is delray beach , florida\n",
      "derrick green attended one school , hermitage high school\n",
      "the player from american heritage school is also from delray beach , florida\n",
      "greg bryant played in the running back position\n",
      "episode 9 , directed by david tucker , was written by kate gartside\n",
      "episode 10 was viewed 6.34 million times\n",
      "the episode that paul marcus was on , aired march 08 , 2009\n",
      "numerical entry 19 is for episode 9\n",
      "kazakhstan has 0 gold\n",
      "tayshaun prince played the forward position\n",
      "daniel inouye has a second place ranking for having an uninterrupted tenure time of 49 years , 394 days\n",
      "the total tenure time of warren magnuson is 36 years , 20 days\n",
      "the team with a record of 34 - 27 had 7 high assists by n. mcmillan\n",
      "the game on march 19th had a score of 112 - 91\n",
      "the song title for track 9 is just a little bit\n",
      "the rider who timed in at 20'50.45 at 108.623 mph on thursday , june 2nd did not have a time for friday , june 3rd\n",
      "ypiranga - sp played 14 games and had a draw of 0\n",
      "ypiranga - sp in position 2 has 22 points had lost 3 matches with no drawn\n",
      "nathan schouteren was the opponent in the match that lasted 4:17\n",
      "carlos alexandre pereira was the opponent at the shooto 17 event\n",
      "the match in moscow , russia resulted in a win in 4:16\n",
      "brian mateer 's speed was 110.152 mph\n",
      "team 250cc honda had the rank number 1 rider with a speed of 111.072 mph\n",
      "necro butcher eliminated greg valentine with a pinfall after a sunset flip\n",
      "chapter six episode is aired in october 27th , 2008\n",
      "chapter five : dressed to kill episode 's rank is 8\n",
      "the episode , chapter six : take the high road , aired on october 27th , 2008\n",
      "the episode , chapter five : dressed to kill , had a weekly rank for living of 8\n",
      "the episode , chapter two : nothing sacred , aired on september 29th , 2008\n",
      "away games against footscray are played at arden street oval\n",
      "the crowd for the game at essendon was 12000\n",
      "the game at the venue of arden street oval was on 25 may 1940\n",
      "the points won for the year 1992 was 1.5\n",
      "the foursomes record in 2002 was 2 - 2 - 0\n",
      "the 1888 / 89 - 1913 / 14 career had 311 wickets , 4564 runs , and 51 matches\n",
      "the 1899 / 00 - 1925 / 26 career had 211 matches with 955 wickets\n",
      "the 1898 / 99 - 1919 / 20 career had 241 wickets and 4476 runs\n",
      "on january 2 , 2005 which was the week 17 , opponent was tampa bay buccaneers and attendance was 31650\n",
      "on january 2 , 2005 which was the week 17 , the attendance for the game against tampa bay buccaneers was 31650\n",
      "december 5 , 2004 was the date of the game after week 12 with 62262 fans attending\n",
      "the vowel i / ɪ , ɨ / has an american pronunciation of ɪ , ə\n",
      "i , e is the symbol for the australian sound that sounds like illyria , cf.cirrhosis\n",
      "there is no 17th century entry of a\n",
      "syllepsis is an example of the american of ɪ , ə , and a semi - closed initial unstressed vowels of y / ɨ /\n",
      "builder numbers 1063 - 1065 with rr class a1 have a year earlier than 1916\n",
      "the rr numbers of hudsweel clarke before 1914 were 15 and 18 - 22\n",
      "shrek was nominated for a tony award in 2009\n",
      "2012 had a nominated result\n",
      "the rider who clocked in at 21'33.76 at 104.987 mpg on wednesday , june 1st ended up clocking in faster at 21'05.87 at 107.300 mph on thursday , june 2nd\n",
      "players larry mize and d. a. are tied for 5th place\n",
      "player fred couples has a score 72 + 67 + 71 = 210\n",
      "mark o'meara had a score of 71 + 72 + 66 = 209\n",
      "fred couples had a score of 72 + 67 + 71 = 210\n",
      "brent yamada (kamloops) , aron herrick (vernom) , and darren heath (vernom) all have 4 wins and 5 losses\n",
      "neil dangerfield (victoria) was the skip who had 43 ends won\n",
      "skip jeff richard (kelowna) has 2 losses\n",
      "on 7 may 1960 , a crowd of 9000 watched the away team , richmond , score 3.8 (26)\n",
      "3.8 (26) was the away team score against a home team that scored 5.12 (42)\n",
      "when ritchmond was the away team the crowd was 14000\n",
      "mystery guest was the nomination in a year earlier than 2009\n",
      "the nomination for the best new artist category happened at the 20th golden melody awards\n",
      "in 2010 - 2011 , 1522 tonnes of c02 was saved\n",
      "the £ saved with 6.9% of electricity reduction is £337000\n",
      "£100000 + saved with 8.9% electricity reduction\n",
      "from 2006 - 07 , 1 university had an electricity reduction of 10%\n",
      "the cosworth straight - 4 engine has the lotus 44 f2 chassis\n",
      "hsbc was the fifth most profitable company overall and most profitable in the uk\n",
      "the usa is the country that has a company with a market value (billion $) of 188.77\n",
      "pal n utilizes 3.582056 mhz where as pal b , g , h utilizes 4.43361875 mhz\n",
      "both ntsc m and pal m are 525 / 60\n",
      "40022 is the lowest attendance during week 11\n",
      "during week four , there were 57814 spectators\n",
      "week 11 fell on november 9 , 1997\n",
      "the quid cup premiership of 2005 was won by north queensland young guns at dairy farmers stadium\n",
      "1996 is the first year in the qld cup when home ground is corbett park , crosby park , lang park , and anz stadium\n",
      "quad park is the home ground for the team sunshine coast falcons\n",
      "the team gold coast vikings have a nil qld cup premiership\n",
      "the team port moresby vipers is located in port moresby\n",
      "the flieger - doppelpistole 1919 originated in switzerland\n",
      "the neal submachine gun was introduced in 1948\n",
      "the area km square (1998) of the voivodeship with the no. of communes at 51 was 6 266\n",
      "the voivodenship also known by the abbreviation kn has an area km square (1998) of 5 139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the record of the match was a 10 - 3 (1) score , resulting in a win in round 5 with a time of 5:00 minutes\n",
      "the opponent , georges st - pierre lost in a (unanimous) decision\n",
      "canton , ohio was the location for the event , fightfest 2 , which lasted only 3 rounds\n",
      "the opponent , diego gonzalez , had a time of 0:19\n",
      "lee doski has a 4 - 2 record\n",
      "paolo quinteros was on the cai zaragoza team that scored 595 points\n",
      "both poland and great britain have fc notes\n",
      "croatia is ranked number 2\n",
      "piotr hojka and jaroslaw godek are rowers for poland which is ranked number 5\n",
      "denmark is third place in the rank\n",
      "sweden has margin of victory of 2 strokes in the 1999 event\n",
      "when north melbourne is the away team , the crowd was 8662\n",
      "carlton is the home team , and south melbourne is the away team\n",
      "essendon is the team with windy hills as their home venue\n",
      "20000 was the crowd of people who watched richmond play as the away team\n",
      "in an away game , 8662 people watched north melbourne play\n",
      "the first time that frank williams racing cars entered a competition was in 1969\n",
      "the ford engine was used from 1969 onward\n",
      "the most recent year in which ron harris / team lotus was an entrant is 1966\n",
      "robert archibald from scotland played in the forward / center position\n",
      "mahmoud abdul - rauf played in the point guard position for the grizzlies in 2000 - 2001\n",
      "7 g of saturated fat has 28 g of polyunsaturated fat\n",
      "the amount of monounsaturated fat is 30 g , while the amount of saturated fat is 15 g\n",
      "parun is located in the province of nurestan\n",
      "there was one foundation date when television channels were canal nou , canal nou dos , and canal nou 24 tvvi\n",
      "the television channel is telemadrid laotra telemadrid sat when the radio station is onda madrid\n",
      "the organization of ente publico radio television madrid (eprtvm) has the radio station onda madrid\n",
      "asturias is the autonomous community with the telivision channels tpa , tpa2 , and rtpa internacional\n",
      "television channels tpa , tpa2 , and rtpa internacional belong to the autonomous community of asturias\n",
      "the glamorous life aired on may 2 , 2010\n",
      "vancouver had a record of 13 - 17 - 3 on december 18\n",
      "vancouver had a record of 11 - 15 - 3 on december 8\n",
      "when philadelphia was the visiting team to vancouver on december 1 , the score was 4 - 5\n",
      "bbc one broadcast the 2012 summer olympics closing ceremony in london and ranked 10th in viewership\n",
      "eastenders ranks fourth in number of viewers and was aired by bbc one\n",
      "on 25 december 1987 , coronation street on itv was ranked 9\n",
      "the highest pick number after round 11 is 326\n",
      "robert geathers from south carolina state had the 84 pick in round 3\n",
      "south melbourne is the away that visited carlton on 24 may 1930\n",
      "windy hill was the venue when essendon was the home team with a score of 14.12 (96)\n",
      "when richmond was the away team , there were 20000 spectators\n",
      "the venue of sale has a distance of 1208 m\n",
      "c symons is the winner / 2nd with 2nd embracing\n",
      "emirates stakes is the race with the jockey d nkilic\n",
      "on may 16th , 2007 there were 6.8 million viewers tuned into the finale\n",
      "season 2 finale aired on tuesday , may 20th 2003 at 8:30 pm\n",
      "in the year august 31 , 1943 , the successor clair engle (d) was seated in the district california 2nd\n",
      "the rows with 14 g and 39 g of saturated fat both have total fat of 100 g and polyunsaturated fat of 11 g\n",
      "the row with 73 g of monounsaturated fat has a smoke point of 100 c and a total fat of 100 g\n",
      "david graham is from australia\n",
      "jack nicklaus had a score of 71 + 74 + 72 + 69 = 286 when he placed t6\n",
      "raymond floyd scored 70 + 73 + 69 + 72 = 284\n",
      "22663 was the amount of money craig stadler won\n",
      "four trains calling at castor , overton , and peterborough east are operated by lnwr\n",
      "in week 13 , the losing result was 41 - 14\n",
      "48 losses of 77 games played have a win percentage of 37.67%\n",
      "out of 15 games played , 0 were tied\n",
      "there were 0 tied with 8 losses and 50% wins\n",
      "scott mccarron from the united states played when the score was 72 + 72 = 144 and tied for 10th place\n",
      "scott mccarron ended up tied for 10th place with a score of 72 + 72 = 144\n",
      "the boxers in round 16 that did not advance in the quarterfinal were barriga 7 - 8 , papilaya 10 - 18 , bae 4 - 5 , and burba l dnf\n",
      "ebrahim mousavi , a middleweight of 75 kg did not advance to the final\n",
      "ali darvish was a light heavyweight of 81 kg\n",
      "rouhollah hosseini did not advance in the final\n",
      "geoffrey fitton had 44 performances\n",
      "channel 4 's april 21 , 2010 airing of you gotta get a gimmick had 2.675 m total viewers\n",
      "the ballad of booth , which aired on june 30 , 2010 on channel 4 , was ranked at 841000 - 2 in e4s rating b\n",
      "being alive first aired on channel 4 on february 3 , 2010\n",
      "everybody ought to have a maid was in the first position on february 24 , 2010 for channel 4s ratings\n",
      "hubert green of the united states won in 1977\n",
      "lee trevino of the united states had a total of 148\n",
      "in 1982 tom watson of the united states had a total of 147\n",
      "petter ronnquist was 264 overall\n",
      "a planet with a radial velocity of 0.089 m / s is likely to be detected by a third - generation spectrograph\n",
      "jupiter is a planet with a semimajor axis of 5.20 and has an orbital period lasting 11.86 years\n",
      "victor yusim michael schneidman won the men 's doubles in 1979 the year after carol silman ben shushan won the women 's doubles\n",
      "vampiro was the winner in mexico city on july 17 , 1992 and december 13 , 2002\n",
      "the wager was hair when vampiro was the winner on august 23 , 1992\n",
      "shocker was the winner in mexico city\n",
      "aaron grundy was the loser in monterrey , nuevo leon\n",
      "when playing amanda brown and brenda remilton , the team won 6 - 1 , 3 - 6 , 6 - 4\n",
      "when playing with elizabeth little , they were the runner up and lost 4 - 6 , 3 - 6\n",
      "there are no entries in the table with 0 latitude\n",
      "18630 people attended the 4 - 2 los angeles game versus vancouver\n",
      "the attendance for the detroit - los angeles game was 17215\n",
      "a first - generation spectrograph can be used to detect the planet jupiter\n",
      "the orbital period of the planet jupiter lasts 11.86 years\n",
      "when newcastle united was the home team , manchester city was the away team\n",
      "newcastle united played home team against manchester city\n",
      "the game on march 16 , 1990 was a loss , and attended by 10551 people\n",
      "the attendance at the march 16 , 1990 game was 10551 and the visiting team lost\n",
      "the record of game 67 is 42 - 14 - 11\n",
      "the score for boston bruins' second game is 2 - 1\n",
      "the show , this hour has 22 minutes , is at 8:00 on the day da vinci 's inquest is on at 9:00\n",
      "chicago hope is at 10:00 on the day that party of five is at 9:30\n",
      "rolla c mcmillen (r) succeeded william h wheat (r) because of the reason that william h wheat (r) died on january 16 , 1944\n",
      "ellsworth b buck (r) was the successor in the 11th district of new york\n",
      "ryan hunter - reay and jimmy vasser both had fewer than two points and grids larger than 4 , and were on the american spirit team johansson team\n",
      "the total number of draws for bridgenorth was 0\n",
      "bridgenorth has the highest number of wins in the ntfa div with 15 wins and only 3 losses\n",
      "susan sarandon was the winner and nominee in 2001\n",
      "bruce willis was nominated for the film rugrats go wild\n",
      "kwadukuza egoli hotel tower 1 , trust bank building has 31 floors and was the tallest from years 1970 - 1973\n",
      "there are no buildings with less than 196 feet\n",
      "the roles for aaron jablonski and schuyler grogan were closed on feb 4 , 1961\n",
      "584\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import json\n",
    "\n",
    "t = pandas.read_csv('/Users/wenhuchen/Downloads/clean/positive.csv')\n",
    "t = t[t.AssignmentStatus==\"Approved\"]\n",
    "\n",
    "print len(t) * 10\n",
    "num = 10\n",
    "positive = {}\n",
    "count = 0\n",
    "for i, row in t.iterrows():\n",
    "    for j in range(1, num + 1):\n",
    "        if row['Answer.A{}'.format(j)] == \"Entailed\":\n",
    "            name = row['Input.url{}'.format(j)].split('/')[-1]\n",
    "            if name in limit_length:\n",
    "                backbone = []\n",
    "                with open('data/all_csv/' + name, 'r') as f:\n",
    "                    lines = []\n",
    "                    for _ in f.readlines():\n",
    "                        for w in _.strip().split('#'):\n",
    "                            lines.extend(w.split(' '))\n",
    "                    #for line in lines[1:]:\n",
    "                    backbone.extend(lines)\n",
    "                count += 1\n",
    "                #print backbone\n",
    "                if name in positive:\n",
    "                    positive[name][0].append(postprocess(row['Input.s{}'.format(j)], backbone))\n",
    "                    positive[name][1].append(1)\n",
    "                else:\n",
    "                    positive[name] = [[postprocess(row['Input.s{}'.format(j)], backbone)], [1]]\n",
    "    if i // 100 == 1:\n",
    "        break\n",
    "\n",
    "print count\n",
    "with open('READY/cleaned_positive.json', 'w') as f:\n",
    "    json.dump(positive, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pandas.read_csv('/Users/wenhuchen/Downloads/Batch_3625238_batch_results.csv')\n",
    "t['Reject'] = t['Reject'].astype('str')\n",
    "\n",
    "for i, row in t.iterrows():\n",
    "    if row['Input.s0'].startswith('the total attendance for week'):\n",
    "        print row['Input.s0']\n",
    "        if row['Answer.A0'] != 'Supported':\n",
    "            t.set_value(i, 'Reject', \"did not pass automatic test\")\n",
    "        else:\n",
    "            t.set_value(i, 'Reject', \"\")\n",
    "    elif row['Input.s0'].startswith('chicago bears has won') or row['Input.s0'].startswith('chicago bears is the best'):\n",
    "        if row['Answer.A0'] != 'Refuted':\n",
    "            t.set_value(i, 'Reject', \"did not pass automatic test\")\n",
    "        else:\n",
    "            t.set_value(i, 'Reject', \"\")\n",
    "    else:\n",
    "        if row['Answer.A0'] != 'Erroneous':\n",
    "            t.set_value(i, 'Reject', \"did not pass automatic test\")\n",
    "        else:\n",
    "            t.set_value(i, 'Reject', \"\")\n",
    "    \n",
    "t.to_csv('/Users/wenhuchen/Downloads/uploading.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ 1-1000181-1.html.csv ------------\n",
      "state / territory : australian capital territory\n",
      "text / background colour : blue / white\n",
      "format : yaa nna\n",
      "current slogan : act celebration of a century 2013\n",
      "current series : yil 00a\n",
      "notes : slogan screenprinted on plate\n",
      "------------ 1-10006830-1.html.csv ------------\n",
      "aircraft : robinson r - 22\n",
      "description : light utility helicopter\n",
      "max gross weight : 1370 lb (635 kg)\n",
      "total disk area : 497 ft square (46.2 m square)\n",
      "max disk loading : 2.6 lb / ft square (14 kg / m square)\n",
      "------------ 1-10007452-3.html.csv ------------\n",
      "order year : 1992 - 93\n",
      "manufacturer : gillig\n",
      "model : phantom (high floor)\n",
      "fleet series (quantity) : 444 - 464 (21)\n",
      "powertrain (engine / transmission) : dd s50egr allison wb - 400r\n",
      "fuel propulsion : diesel\n",
      "------------ 1-10015132-1.html.csv ------------\n",
      "player : quincy acy\n",
      "no : 4\n",
      "nationality : united states\n",
      "position : forward\n",
      "years in toronto : 2012 - present\n",
      "school / club team : baylor\n",
      "------------ 1-10015132-14.html.csv ------------\n",
      "player : patrick o'bryant\n",
      "no : 13\n",
      "nationality : united states\n",
      "position : center\n",
      "years in toronto : 2009 - 10\n",
      "school / club team : bradley\n",
      "------------ 1-10015132-2.html.csv ------------\n",
      "player : mark baker\n",
      "no : 3\n",
      "nationality : united states\n",
      "position : guard\n",
      "years in toronto : 1998 - 99\n",
      "school / club team : ohio state\n",
      "------------ 1-10015132-21.html.csv ------------\n",
      "player : john wallace\n",
      "no : 44\n",
      "nationality : united states\n",
      "position : forward\n",
      "years in toronto : 1997 - 99\n",
      "school / club team : syracuse\n",
      "------------ 1-10015132-3.html.csv ------------\n",
      "player : josé calderón\n",
      "no : 8\n",
      "nationality : spain\n",
      "position : guard\n",
      "years in toronto : 2005 - 2013\n",
      "school / club team : tau cerámica (spain)\n",
      "------------ 1-10015132-7.html.csv ------------\n",
      "player : sundiata gaines\n",
      "no : 2\n",
      "nationality : united states\n",
      "position : guard\n",
      "years in toronto : 2011\n",
      "school / club team : georgia\n",
      "------------ 1-10020178-1.html.csv ------------\n",
      "name : grande dixence\n",
      "canton : valais\n",
      "height (meters) : 285\n",
      "crest length (meters) : 695\n",
      "type : gravity\n",
      "year of construction : 1961\n",
      "name of the lake : lac des dix\n",
      "------------ 1-10021158-3.html.csv ------------\n",
      "year : 2005\n",
      "tournaments played : 1\n",
      "cuts made : 1\n",
      "wins : 0\n",
      "2nd : 0\n",
      "top 10s : 0\n",
      "best finish : t69\n",
      "earnings ($) : 2525\n",
      "money list rank : n / a\n",
      "scoring average : 75.0\n",
      "scoring rank : n / a\n",
      "------------ 1-1004033-1.html.csv ------------\n",
      "season : 1996\n",
      "player : steve ralston\n",
      "position : midfielder\n",
      "nationality : united states\n",
      "team : tampa bay mutiny\n",
      "draft pick : 18\n",
      "draft class : 1996 mls college draft\n",
      "college : florida international\n",
      "------------ 1-100518-1.html.csv ------------\n",
      "name : kubera\n",
      "direction : north\n",
      "mantra : oṃ śaṃ kuberāya namaḥ\n",
      "weapon : gadā (mace)\n",
      "consort : kuberajāyā\n",
      "graha (planet) : budha ( mercury )\n",
      "guardian mātṛkā : kumārī\n",
      "------------ 1-10054296-1.html.csv ------------\n",
      "member : alpha nu omega\n",
      "headquarters : baltimore , maryland\n",
      "classification : fraternity & sorority\n",
      "chapters : 26\n",
      "founded : 1988 at morgan state university\n",
      "uccfs : 2006\n",
      "------------ 1-1007688-1.html.csv ------------\n",
      "year : 1913\n",
      "typhus : 120\n",
      "typhoid fever : 424\n",
      "relapsing fever : 30\n",
      "smallpox : 67\n",
      "malaria : 3600\n",
      "------------ 1-10082596-1.html.csv ------------\n",
      "school : indiana university\n",
      "location : bloomington , in\n",
      "founded : 1820\n",
      "affiliation : public\n",
      "enrollment : 40354\n",
      "team nickname : hoosiers\n",
      "primary conference : big ten conference ( d - i )\n",
      "------------ 1-1008653-9.html.csv ------------\n",
      "country ( exonym ) : iceland\n",
      "capital ( exonym ) : reykjavík\n",
      "country ( endonym ) : ísland\n",
      "capital ( endonym ) : reykjavík\n",
      "official or native language (s) (alphabet / script) : icelandic\n",
      "------------ 1-1009087-1.html.csv ------------\n",
      "season : 1st\n",
      "network : upn\n",
      "season premiere : september 11 , 2000\n",
      "season finale : may 14 , 2001\n",
      "tv season : 2000 - 2001\n",
      "ranking : 136\n",
      "viewers (in millions) : 4.0\n",
      "------------ 1-1011906-1.html.csv ------------\n",
      "regional county municipality (rcm) : acton\n",
      "population canada 2011 census : 15381\n",
      "land area : km2 (sqmi)\n",
      "density (pop. per km2) : 26.5\n",
      "seat of rcm : acton vale\n",
      "------------ 1-101196-1.html.csv ------------\n",
      "county : county donegal\n",
      "english name : altnapeaste\n",
      "irish name : alt na péiste\n",
      "population : 188\n",
      "irish speakers : 55%\n",
      "------------ 1-10120207-8.html.csv ------------\n",
      "season : 1\n",
      "timeslot ( et ) : wednesday 9:00 pm\n",
      "season premiere : september 5 , 2001\n",
      "season finale : december 13 , 2001\n",
      "tv season : 2001 - 2002\n",
      "rank : 73\n",
      "viewers (millions) : 8.8\n",
      "------------ 1-10121127-1.html.csv ------------\n",
      "un operation name : none\n",
      "un operation title : un consular commission\n",
      "location : indonesia\n",
      "dates of australian involvement : 1947\n",
      "number of australians involved : 4\n",
      "australian role : military observers\n",
      "------------ 1-1012730-1.html.csv ------------\n",
      "year : 1978\n",
      "starts : 5\n",
      "wins : 0\n",
      "top 5 : 1\n",
      "top 10 : 3\n",
      "poles : 0\n",
      "avg. start : 16.2\n",
      "avg. finish : 11.4\n",
      "winnings : $21395\n",
      "position : 39th\n",
      "team (s) : hagan racing\n",
      "------------ 1-1012730-2.html.csv ------------\n",
      "year : 1985\n",
      "starts : 1\n",
      "wins : 1\n",
      "top 5 : 1\n",
      "top 10 : 1\n",
      "poles : 0\n",
      "avg. start : 14.0\n",
      "avg. finish : 1.0\n",
      "winnings : $32400\n",
      "position : 101st\n",
      "team (s) : darrell waltrip motorsports\n",
      "------------ 1-10128185-2.html.csv ------------\n",
      "song : groovy chick\n",
      "mobiles : 10\n",
      "northern ireland : 3\n",
      "northern england : 2\n",
      "scotland : 3\n",
      "southern england : 2\n",
      "wales : 3\n",
      "total : 23\n",
      "------------ 1-1013129-1.html.csv ------------\n",
      "pick : 1\n",
      "player : ed jovanovski\n",
      "position : defence\n",
      "nationality : canada\n",
      "nhl team : florida panthers\n",
      "college / junior / club team : windsor spitfires ( ohl )\n",
      "------------ 1-1013129-10.html.csv ------------\n",
      "pick : 235\n",
      "player : tero lehtera\n",
      "position : centre\n",
      "nationality : finland\n",
      "nhl team : florida panthers\n",
      "college / junior / club team : kiekko - espoo (finland)\n",
      "------------ 1-1013129-11.html.csv ------------\n",
      "pick : 261\n",
      "player : per gustafsson\n",
      "position : defence\n",
      "nationality : sweden\n",
      "nhl team : florida panthers\n",
      "college / junior / club team : hv71 (sweden)\n",
      "------------ 1-1013129-8.html.csv ------------\n",
      "pick : 183\n",
      "player : jason boudrias\n",
      "position : forward\n",
      "nationality : canada\n",
      "nhl team : florida panthers\n",
      "college / junior / club team : laval titan (qmjhl)\n",
      "------------ 1-1013168-2.html.csv ------------\n",
      "state (class) : arkansas (2)\n",
      "vacator : john l. mcclellan (d)\n",
      "reason for change : died november 28 , 1977\n",
      "successor : kaneaster hodges , jr. (d)\n",
      "date of successors formal installation : december 10 , 1977\n",
      "------------ 1-1013168-3.html.csv ------------\n",
      "district : louisiana 1st\n",
      "vacator : richard a. tonry (d)\n",
      "reason for change : forced to resign may 4 , 1977\n",
      "successor : bob livingston (r)\n",
      "date successor seated : august 27 , 1977\n",
      "------------ 1-101336-1.html.csv ------------\n",
      "formula : yba 2 cu 3 o 7\n",
      "notation : 123\n",
      "t c (k) : 92\n",
      "no. of cu - o planes in unit cell : 2\n",
      "crystal structure : orthorhombic\n",
      "------------ 1-1014319-1.html.csv ------------\n",
      "week : 1\n",
      "dance / song : cha - cha - cha / ain't no mountain high enough\n",
      "horwood : 7\n",
      "goodman : 8\n",
      "dixon : 8\n",
      "tonioli : 8\n",
      "total : 31\n",
      "result : n / a\n",
      "------------ 1-1015421-1.html.csv ------------\n",
      "class : class 170 / 1\n",
      "operator : crosscountry\n",
      "no. built : 17\n",
      "year built : 1998 - 1999\n",
      "cars per set : 3\n",
      "unit nos : 170 101 - 170 110\n",
      "------------ 1-1015914-15.html.csv ------------\n",
      "Unnamed: 0 : you sg\n",
      "kalau kawau ya : ngi\n",
      "kawalgau ya : ngi\n",
      "kalaw lagaw ya : ni\n",
      "kulkalgau ya : ni\n",
      "kauraraigau ya (kowrareg) : ngi\n",
      "------------ 1-1015914-24.html.csv ------------\n",
      "case / suffix : nom - acc - inst\n",
      "we two : ngalbe\n",
      "you and i : ngba\n",
      "you two : ngipel\n",
      "them two (the two) : palai (boigu pale)\n",
      "who - two : ngawal\n",
      "------------ 1-10160447-1.html.csv ------------\n",
      "position : 1\n",
      "driver : mark martin\n",
      "points : 61\n",
      "winnings : $225000\n",
      "series : nascar winston cup\n",
      "------------ 1-101942-2.html.csv ------------\n",
      "Unnamed: 0 : ages 5 - 11\n",
      "all children (000s) : 838800\n",
      "economically active children (000s) : 109700\n",
      "economically active children (%) : 13.1\n",
      "child labour (000s) : 109700\n",
      "child labour (%) : 13.1\n",
      "children in hazardous work (000s) : 60500\n",
      "children in hazardous work (%) : 7.2\n",
      "------------ 1-10236830-1.html.csv ------------\n",
      "nomination : best actor in a leading role\n",
      "actors name : georgiy drozd\n",
      "film name : marrying death\n",
      "director : nikolay maschenko\n",
      "country : ukraine\n",
      "------------ 1-10236830-4.html.csv ------------\n",
      "nomination : best actor in a leading role\n",
      "actors name : yuriy dubrovin\n",
      "film name : okraina\n",
      "director : pyotr lutsik\n",
      "country : ukraine\n",
      "------------ 1-10236830-6.html.csv ------------\n",
      "nomination : best actor in a leading role\n",
      "actors name : piotr adamczyk\n",
      "film name : chopin : desire for love\n",
      "director : jerzy antczak\n",
      "country : poland\n",
      "------------ 1-10240125-1.html.csv ------------\n",
      "season : 1908 - 09\n",
      "division : division two\n",
      "league apps : 15\n",
      "league goals : 1\n",
      "fa cup apps : 0\n",
      "fa cup goals : 0\n",
      "total apps : 15\n",
      "total goals : 1\n",
      "------------ 1-10240125-2.html.csv ------------\n",
      "season : 1913 - 14\n",
      "division : division one\n",
      "league apps : 23\n",
      "league goals : 1\n",
      "fa cup apps : 7\n",
      "fa cup goals : 4\n",
      "total apps : 30\n",
      "total goals : 5\n",
      "------------ 1-10262329-1.html.csv ------------\n",
      "assembly type : flex - on - glass (fog)\n",
      "adhesive type : epoxy\n",
      "time (sec) : 10 - 12\n",
      "temp (°c) : 170 - 200\n",
      "pressure : 2 - 4 mpa▲\n",
      "------------ 1-10264179-2.html.csv ------------\n",
      "round : 1\n",
      "circuit : fuji speedway\n",
      "date : 2 april\n",
      "pole position : benoît tréluyer\n",
      "fastest lap : masataka yanagida\n",
      "winning driver : benoît tréluyer\n",
      "winning team : mobilecast impul\n",
      "------------ 1-10269427-3.html.csv ------------\n",
      "episode : 27\n",
      "production code : 201\n",
      "title : deja foo\n",
      "directed by : mark ackland\n",
      "written by : sib ventress\n",
      "airdate : march 17 , 2008\n",
      "------------ 1-1028356-3.html.csv ------------\n",
      "outcome : winner\n",
      "year : 1987\n",
      "championship : australian open\n",
      "surface : grass\n",
      "partner : sherwood stewart\n",
      "opponents : anne hobbs andrew castle\n",
      "score : 3 - 6 , 7 - 6 (5) , 6 - 3\n",
      "------------ 1-10295819-1.html.csv ------------\n",
      "player : ričardas berankis\n",
      "current singles ranking : 68\n",
      "current doubles ranking : 515\n",
      "first year played : 2007\n",
      "ties played : 13\n",
      "total w - l : 17 - 9\n",
      "singles w - l : 14 - 5\n",
      "doubles w - l : 3 - 4\n",
      "------------ 1-103084-4.html.csv ------------\n",
      "year : 1999\n",
      "broadcast date : 12 march\n",
      "bbc one total viewing : 6830000\n",
      "bbc one rank : 20th\n",
      "bbc two total viewing : 3130000\n",
      "bbc two rank : 13th\n",
      "------------ 1-10312547-1.html.csv ------------\n",
      "character : peter pan\n",
      "1954 broadway : mary martin\n",
      "1955 broadcast : mary martin\n",
      "1960 broadcast : mary martin\n",
      "1979 broadway : sandy duncan\n",
      "1990 broadway : cathy rigby\n",
      "1991 broadway : cathy rigby\n",
      "1998 broadway : cathy rigby\n",
      "1999 broadway : cathy rigby\n",
      "------------ 1-10321124-1.html.csv ------------\n",
      "↓ function / genus → : needle monomer\n",
      "shigella : mxih\n",
      "salmonella : prgi\n",
      "yersinia : yscf\n",
      "escherichia : escf\n",
      "------------ 1-10335-1.html.csv ------------\n",
      "camp : auschwitz - birkenau\n",
      "estimated deaths : 1100000\n",
      "operational : may 1940 - january 1945\n",
      "occupied territory : poland\n",
      "current country of location : poland\n",
      "primary means for mass killings : zyklon b gas chambers\n",
      "------------ 1-10360656-1.html.csv ------------\n",
      "round : 1\n",
      "choice : 1\n",
      "overall : 1\n",
      "player name : tommy mason\n",
      "position : running back\n",
      "college : tulane\n",
      "------------ 1-10360823-1.html.csv ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round : 1\n",
      "choice : 3\n",
      "overall : 3\n",
      "player name : jim dunaway\n",
      "position : defensive tackle\n",
      "college : mississippi\n",
      "------------ 1-10361230-1.html.csv ------------\n",
      "round : 1\n",
      "choice : 25\n",
      "overall : 25\n",
      "player name : john ward\n",
      "position : offensive tackle\n",
      "college : oklahoma state\n",
      "------------ 1-10361453-2.html.csv ------------\n",
      "game : 1\n",
      "date : sept. 15\n",
      "opponent : green bay packers\n",
      "result : win\n",
      "vikings points : 32\n",
      "opponents : 17\n",
      "record : 1 - 0\n",
      "attendance : 56267\n",
      "------------ 1-10361625-1.html.csv ------------\n",
      "round : 1\n",
      "choice : 27\n",
      "overall : 27\n",
      "player name : tommy kramer\n",
      "position : quarterback\n",
      "college : rice\n",
      "------------ 1-1036189-1.html.csv ------------\n",
      "headstamp id : vii or viiz\n",
      "primer annulus color : purple\n",
      "bullet tip color : none\n",
      "other features : none\n",
      "functional type : light ball\n",
      "------------ 1-1037590-1.html.csv ------------\n",
      "year : 2002\n",
      "games : 14\n",
      "games started : 12\n",
      "completions : 215\n",
      "attempts : 429\n",
      "completion % : 50.1\n",
      "yards : 2294\n",
      "yards / attempt : 5.3\n",
      "touchdowns : 12\n",
      "interceptions : 16\n",
      "rating : 59.9\n",
      "------------ 1-10392906-2.html.csv ------------\n",
      "week : 1\n",
      "date : saturday , april 14\n",
      "kickoff : 7:00 p.m\n",
      "opponent : frankfurt galaxy\n",
      "final score : l 14 - 30\n",
      "team record : 0 - 1\n",
      "game site : commerzbank - arena\n",
      "attendance : 38125\n",
      "------------ 1-10399701-2.html.csv ------------\n",
      "school year : 1990 - 91\n",
      "class a : menard\n",
      "class aa : coleman\n",
      "class aaa : la grange\n",
      "class aaaa : burkburnett\n",
      "class aaaaa : round rock\n",
      "------------ 1-10402018-1.html.csv ------------\n",
      "character : tick (mitzi)\n",
      "australia & new zealand (sydney - first run , melbourne , auckland) : jeremy stanford\n",
      "london : jason donovan\n",
      "toronto / broadway : will swenson\n",
      "brazil : luciano andrey\n",
      "uk tour : jason donovan , noel sullivan\n",
      "us tour : wade mccollum\n",
      "italy (milan , rome , trieste) : antonello angiolillo\n",
      "------------ 1-10413597-4.html.csv ------------\n",
      "no. in series : 21\n",
      "no. in season : 1\n",
      "title : civil unrest\n",
      "setting : 30th may 1536\n",
      "directed by : ciaran donnelly\n",
      "written by : michael hirst\n",
      "original air date : april 5 , 2009\n",
      "------------ 1-10413597-5.html.csv ------------\n",
      "no. in series : 29\n",
      "no. in season : 1\n",
      "title : moment of nostalgia\n",
      "setting : summer 1540\n",
      "directed by : dearbhla walsh\n",
      "written by : michael hirst\n",
      "u.s. viewers (million) : 0.88\n",
      "original air date : april 11 , 2010\n",
      "------------ 1-10420426-1.html.csv ------------\n",
      "season : 2005\n",
      "series : formula renault 2.0 germany\n",
      "team : motopark oschersleben\n",
      "races : 14\n",
      "wins : 4\n",
      "poles : 6\n",
      "f / laps : 5\n",
      "podiums : 8\n",
      "points : 273\n",
      "position : 3rd\n",
      "------------ 1-1046071-1.html.csv ------------\n",
      "year : 1994\n",
      "division : 3\n",
      "league : usisl\n",
      "regular season : 1st , northeast\n",
      "playoffs : sizzling nine\n",
      "open cup : did not enter\n",
      "------------ 1-1046454-1.html.csv ------------\n",
      "year : 2003\n",
      "division : 4\n",
      "league : usl pdl\n",
      "regular season : 4th , southwest\n",
      "playoffs : did not qualify\n",
      "open cup : did not qualify\n",
      "------------ 1-10470082-3.html.csv ------------\n",
      "no : 14\n",
      "- : 1\n",
      "title : the tale of the final wish\n",
      "director : d. j. machale\n",
      "writer : chloe brown\n",
      "us air date : june 19 , 1993\n",
      "storyteller : kristen\n",
      "villains : the sandman\n",
      "------------ 1-10470082-4.html.csv ------------\n",
      "no : 27\n",
      "- : 1\n",
      "title : the tale of the midnight ride\n",
      "director : d. j. machale\n",
      "writer : darren kotania\n",
      "us air date : january 8 , 1994\n",
      "storyteller : tucker\n",
      "villains : brad & the headless horseman\n",
      "------------ 1-10470082-5.html.csv ------------\n",
      "no : 40\n",
      "- : 1\n",
      "title : the tale of the renegade virus\n",
      "director : ron oliver\n",
      "writer : andrew mitchell & gerard lewis\n",
      "us air date : october 1 , 1994\n",
      "storyteller : gary\n",
      "villains : the virus\n",
      "------------ 1-10470082-6.html.csv ------------\n",
      "no : 53\n",
      "- : 1\n",
      "title : the tale of the dead man 's float\n",
      "director : d. j. machale\n",
      "writer : will dixon\n",
      "us air date : october 7 , 1995\n",
      "storyteller : stig\n",
      "villains : the pool zombie\n",
      "------------ 1-10470082-7.html.csv ------------\n",
      "no : 66\n",
      "- : 1\n",
      "title : the tale of the forever game\n",
      "director : iain patterson\n",
      "writer : mark d. perry\n",
      "us air date : february 6 , 1999\n",
      "storyteller : tucker\n",
      "villains : nathaniel & the burden beast\n",
      "------------ 1-10470082-8.html.csv ------------\n",
      "no : 79\n",
      "- : 1\n",
      "title : the tale of the silver sight , part 1\n",
      "director : mark soulard\n",
      "writer : d. j. machale\n",
      "us air date : april 2 , 2000\n",
      "storyteller : n / a\n",
      "villains : the evil spirit\n",
      "------------ 1-10494429-3.html.csv ------------\n",
      "Unnamed: 0 : singular\n",
      "case : nom\n",
      "1st person : ég\n",
      "2nd person : þú\n",
      "masculine : hann\n",
      "feminine : hún\n",
      "neuter : það\n",
      "------------ 1-10527215-3.html.csv ------------\n",
      "rd : 1\n",
      "name : datsun twin 200\n",
      "pole position : johnny rutherford\n",
      "fastest lap : unknown\n",
      "winning driver : johnny rutherford\n",
      "winning team : chaparral\n",
      "report : report\n",
      "------------ 1-10528691-4.html.csv ------------\n",
      "model : 4000\n",
      "introduction : november 1997\n",
      "discontinued : may 1999\n",
      "cpu speed : 100 mhz\n",
      "print resolution (dpi) resolution is given in dots per inch (dpi) : 1200\n",
      "print speed (ppm) : 17\n",
      "standard memory : 4 mb\n",
      "maximum memory : 100 mb\n",
      "------------ 1-1053802-1.html.csv ------------\n",
      "region / country : arab world\n",
      "local title : الوادي al wadi (celebrity format)\n",
      "network : lbc\n",
      "winners : season 1 , 2005: meshari el ballam\n",
      "main presenters : karen derkaloustian (season 1)\n",
      "------------ 1-10556257-1.html.csv ------------\n",
      "season : 1923 - 24\n",
      "team : swindon town\n",
      "league apps : 5\n",
      "league goals : 3\n",
      "cup apps : 5\n",
      "cup goals : 2\n",
      "------------ 1-10566855-1.html.csv ------------\n",
      "season : 1960\n",
      "premier : melbourne\n",
      "runner - up : collingwood\n",
      "score : 8.14 (62) - 2.2 (14)\n",
      "margin : 48\n",
      "venue : mcg\n",
      "attendance : 97457\n",
      "------------ 1-10568553-1.html.csv ------------\n",
      "county : norfolk\n",
      "location : stoughton\n",
      "street names : pleasant street turnpike street lindelof avenue\n",
      "milepost : 3.0\n",
      "roads intersected : route 24\n",
      "notes : route 24 exit 20\n",
      "------------ 1-1057262-1.html.csv ------------\n",
      "commodity : cattle and calves\n",
      "2001 - 02 : 6617\n",
      "2002 - 03 : 5849\n",
      "2003 - 04 : 6345\n",
      "2004 - 05 : 7331\n",
      "2005 - 06 : 7082\n",
      "2006 - 07 : 6517\n",
      "------------ 1-1057316-1.html.csv ------------\n",
      "serial number : unknown\n",
      "wheel arrangement ( whyte notation ) : 4 - 4 - 0\n",
      "build date : october 1856\n",
      "operational owner (s) : western and atlantic railroad 49 texas\n",
      "disposition : static display in grant park , atlanta , georgia\n",
      "------------ 1-10577579-2.html.csv ------------\n",
      "institution : dillard university\n",
      "location : new orleans , louisiana\n",
      "mens nickname : bleu devils\n",
      "womens nickname : lady bleu devils\n",
      "founded : 1869\n",
      "type : private / (methodist & church of christ)\n",
      "enrollment : 900\n",
      "joined : 1981\n",
      "------------ 1-10577579-3.html.csv ------------\n",
      "institution : belhaven college\n",
      "location : jackson , mississippi\n",
      "mens nickname : blazers\n",
      "womens nickname : blazers\n",
      "founded : 1883\n",
      "type : private / (presbyterian church usa)\n",
      "enrollment : 1500\n",
      "joined : 1981 2002\n",
      "left : 2000 2010\n",
      "current conference : ssac\n",
      "classification : naia division i\n",
      "------------ 1-10580575-1.html.csv ------------\n",
      "Unnamed: 0 : 2004\n",
      "capita : 67.0\n",
      "prim. energy : 1696\n",
      "production : 3233\n",
      "export : 1530\n",
      "electricity : 137\n",
      "co 2 - emission : 369\n",
      "------------ 1-10581768-2.html.csv ------------\n",
      "institution : alice lloyd college\n",
      "nickname : eagles\n",
      "location : pippa passes , kentucky\n",
      "founded : 1923\n",
      "type : private\n",
      "enrollment : 600\n",
      "------------ 1-10592536-8.html.csv ------------\n",
      "team : manchester city\n",
      "outgoing manager : stuart pearce\n",
      "manner of departure : contract terminated\n",
      "date of vacancy : 14 may 2007\n",
      "replaced by : sven - göran eriksson\n",
      "date of appointment : 6 july 2007\n",
      "position in table : pre - season\n",
      "------------ 1-10595672-1.html.csv ------------\n",
      "date : january 2\n",
      "opponent : battle creek knights\n",
      "home / away : away\n",
      "score : 113 - 120\n",
      "high points : stanley thomas (23)\n",
      "high rebounds : michael o'neal (8)\n",
      "high assists : imari sawyer (7)\n",
      "location / attendance : kellogg arena (1257)\n",
      "record : 0 - 1\n",
      "------------ 1-1059743-1.html.csv ------------\n",
      "rank : 1\n",
      "member association : saudi arabia\n",
      "points : 860.5\n",
      "group stage : 4\n",
      "play - off : 0\n",
      "afc cup : 0\n",
      "------------ 1-10602294-1.html.csv ------------\n",
      "name : 01\n",
      "dates active : october 12 - october 13\n",
      "peak classification : tropicaldisturbance\n",
      "windspeeds : 45 km / h (30 mph)\n",
      "pressure : 1005hpa (29.68inhg)\n",
      "areas affected : none\n",
      "damage (usd) : none\n",
      "deaths : none\n",
      "refs : none\n",
      "------------ 1-10610087-3.html.csv ------------\n",
      "no. in series : 14\n",
      "no. in season : 1\n",
      "title : voicemail\n",
      "directed by : jace alexander\n",
      "written by : denis leary and peter tolan\n",
      "original air date : june 21 , 2005\n",
      "------------ 1-10610087-6.html.csv ------------\n",
      "no. in series : 40\n",
      "no. in season : 1\n",
      "title : babyface\n",
      "directed by : peter tolan\n",
      "written by : denis leary and peter tolan\n",
      "original air date : june 13 , 2007\n",
      "------------ 1-10621256-1.html.csv ------------\n",
      "player : h j h marshall\n",
      "matches : 11\n",
      "inns : 21\n",
      "n / o : 1\n",
      "runs : 1218\n",
      "high score : 168\n",
      "average : 60.9\n",
      "100 : 5\n",
      "50 : 7\n",
      "catches : 6\n",
      "stump : 0\n",
      "------------ 1-106367-2.html.csv ------------\n",
      "general election : 1970\n",
      "of candidates : 108\n",
      "of seats won : 7\n",
      "% of popular vote : 23.06%\n",
      "result : liberal majority\n",
      "------------ 1-10646790-2.html.csv ------------\n",
      "week : 1\n",
      "date : september 14 , 1969\n",
      "opponent : denver broncos\n",
      "result : l 35 - 7\n",
      "stadium : mile high stadium\n",
      "record : 0 - 1\n",
      "attendance : 43679\n",
      "------------ 1-10647401-1.html.csv ------------\n",
      "week : 1\n",
      "opponent : cleveland browns\n",
      "result : w 34 - 17\n",
      "stadium : schaefer stadium\n",
      "record : 1 - 0\n",
      "attendance : 49222\n",
      "------------ 1-10647639-1.html.csv ------------\n",
      "week : 1\n",
      "date : september 8 , 1985\n",
      "opponent : green bay packers\n",
      "result : w 26 - 20\n",
      "game site : sullivan stadium\n",
      "record : 1 - 0\n",
      "attendance : 49488\n",
      "------------ 1-10650711-1.html.csv ------------\n",
      "pick : 21\n",
      "nfl team : cleveland browns\n",
      "player : clifford charlton\n",
      "position : outside linebacker\n",
      "college : florida\n",
      "------------ 1-10664957-2.html.csv ------------\n",
      "1st players choice : bb b\n",
      "2nd players choice : r bb\n",
      "probability 1st player wins : 0.11%\n",
      "probability 2nd player wins : 99.49%\n",
      "probability of a draw : 0.40%\n",
      "------------ 1-1067134-1.html.csv ------------\n",
      "dvd name : season one\n",
      "of ep : 10\n",
      "region 1 : july 11 , 2006\n",
      "region 2 : september 3 , 2007\n",
      "region 4 : july 18 , 2007\n",
      "------------ 1-1067441-1.html.csv ------------\n",
      "province : south holland\n",
      "population (2004 estimate) : 3453000\n",
      "area (km square) : 2860\n",
      "density : 1207.3\n",
      "gdp (2003 , pps in mil. ) : 95868\n",
      "gdp per cap. (2003 , in ) : 27825\n",
      "------------ 1-10701133-1.html.csv ------------\n",
      "no. in series : 73\n",
      "no. in season : 1\n",
      "title : the beginning of the end\n",
      "directed by : jack bender\n",
      "written by : damon lindelof & carlton cuse\n",
      "featured character (s) : hurley\n",
      "original air date : january 31 , 2008\n",
      "u.s. viewers (million) : 16.07\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "\n",
    "with open('data/short_subset.txt') as f:\n",
    "    limit_length = [_.strip() for _ in f.readlines()]\n",
    "\n",
    "for j, f in enumerate(limit_length):\n",
    "    print \"------------\", f, \"------------\"\n",
    "    t = pandas.read_csv('data/all_csv/' + f, '#')\n",
    "    for i in t.columns:\n",
    "        print i, \":\", t.at[0, i]\n",
    "    if j > 100:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
